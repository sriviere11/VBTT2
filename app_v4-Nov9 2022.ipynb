{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#functions to deal with creating and extracting features\n",
    "\n",
    "#import bamboolib as bam\n",
    "\n",
    "# import bamboolib as bam\n",
    "# import bamboolib as bam\n",
    "from datetime import datetime, timedelta\n",
    "#from VBTT2_IO.IO import  read_config_file\n",
    "\n",
    "# import bamboolib as bam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from yahoo_fin import stock_info as si\n",
    "\n",
    "\n",
    "def get_yf_dataframe(data, nbdays):\n",
    "    yesterday = datetime.now()  # we want data up to yesterday\n",
    "    start_date = yesterday - timedelta(days=nbdays)  # we run the model using data for nbdays\n",
    "    df_res = pd.DataFrame()\n",
    "    #print(\"data in module get_yf_dataframe\", data)\n",
    "    #print(\"nbdays in  in module get_yf_dataframe\", nbdays)\n",
    "    for ticker in data:\n",
    "        df_tmp = si.get_data(ticker, start_date, yesterday)\n",
    "        df_res[ticker] = df_tmp['close']\n",
    "    return df_res\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(ticker, additional_data, days):\n",
    "    #this function return a matrix of features augmented with fix data for number of days\n",
    "    print (\"preprocing module ticker\",ticker)\n",
    "    print(\"preprocessing module additional data\",additional_data)\n",
    "    print(\"preprocessing module days\", days)\n",
    "    tickers_in_sector_extended = np.concatenate((ticker, additional_data), axis=None)\n",
    "    tickers_in_sector_extended = tickers_in_sector_extended.tolist()\n",
    "    matrix_features_sector = get_yf_dataframe(tickers_in_sector_extended, days)\n",
    "    # import pandas as pd; import numpy as np\n",
    "    # matrix_features_sector = matrix_features_sector.reset_index()\n",
    "    matrix_features_sector = matrix_features_sector.reindex(sorted(matrix_features_sector.columns), axis=1)\n",
    "\n",
    "    ###################################\n",
    "    ##### saving and reading features - can help increase processing time\n",
    "    ##### to evaluate on future version\n",
    "    ####################################\n",
    "    # matrix_features_sector.to_csv(\"matrix_features_sector.csv\")\n",
    "    # matrix_features_sector=pd.read_csv(\"matrix_features_sector.csv\")\n",
    "\n",
    "    return matrix_features_sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_train_test_set(ticker, features, lags,additional_data,days,nb_predict_days):\n",
    "    # creating train and test set\n",
    "    yesterday, start_date, train_date_start, train_date_last, test_date_start, test_date_last, days = initialize_data(\n",
    "        days,\n",
    "        lags,\n",
    "        nb_predict_days)\n",
    "\n",
    "    df = features[[ticker] + additional_data]\n",
    "    df_lagged = df.copy()\n",
    "    for window in range(1, lags + 1):\n",
    "        shifted = df.shift(window)\n",
    "        shifted.columns = [x + \"_lag\" + str(window) for x in df.columns]\n",
    "\n",
    "        df_lagged = pd.concat((df_lagged, shifted), axis=1)\n",
    "    #df_lagged = df_lagged.fillna(method='ffill')\n",
    "    df_lagged= df_lagged.interpolate(method='linear')\n",
    "    df_lagged = df_lagged.dropna()\n",
    "    #df_lagged = df_lagged.reindex(sorted(df_lagged.columns), axis=1)\n",
    "\n",
    "    # print(df_lagged)\n",
    "    # df_lagged[ticker+\"_2labels\"]=np.floor(df_lagged[ticker]/df_lagged[ticker+\"_lag1\"]).astype(int)\n",
    "\n",
    "    # train_set\n",
    "    df_filtered = df_lagged.loc[:train_date_last]\n",
    "    # X_train=df_filtered.drop(columns=[ticker, ticker+\"_2labels\"])\n",
    "    X_train = df_filtered.drop(columns=[ticker])\n",
    "    # y_train=df_filtered[ticker+\"_2labels\"]\n",
    "    y_train = df_filtered[ticker]\n",
    "\n",
    "    # test set\n",
    "    df_filtered = df_lagged.loc[test_date_start:test_date_last]\n",
    "    # X_test=df_filtered.drop(columns=[ticker, ticker+\"_2labels\"])\n",
    "    X_test = df_filtered.drop(columns=[ticker])\n",
    "    # y_test=df_filtered[ticker+\"_2labels\"]\n",
    "    y_test = df_filtered[ticker]\n",
    "\n",
    "    # we convert to numpy array\n",
    "    X_train = X_train.to_numpy()\n",
    "    y_train = y_train.to_numpy()\n",
    "    X_test = X_test.to_numpy()\n",
    "    y_test = y_test.to_numpy()\n",
    "    return X_train, y_train, X_test, y_test, df_filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def initialize_data(days, lags, nb_predict_days):\n",
    "\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "\n",
    "    # define main date in models for defining training and test sets dates.\n",
    "    #yesterday = datetime.now() - timedelta(1)\n",
    "    yesterday=datetime.now()\n",
    "    start_date = yesterday - timedelta(days=days)\n",
    "    train_date_start = start_date.strftime(\"%Y-%m-%d\")\n",
    "    train_date_last = yesterday - timedelta(days=nb_predict_days + 1)  # nombre de jours a predire\n",
    "    train_date_last = train_date_last.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    test_date_start = yesterday - timedelta(days=nb_predict_days)\n",
    "    test_date_start = test_date_start.strftime(\"%Y-%m-%d\")\n",
    "    test_date_last = yesterday.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    return yesterday, start_date, train_date_start, train_date_last, test_date_start, test_date_last,days\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_predict_set(ticker ,features ,lags, nb_predict_days, additional_data):\n",
    "\n",
    "    yesterday, start_date, train_date_start, train_date_last, test_date_start, test_date_last, days = initialize_data(\n",
    "        lags * 2, lags, nb_predict_days)\n",
    "    #  List of features X_train, y_train, X_test,y_test\n",
    "    print(\"features shape in module create_predict_set\")\n",
    "    print(features.shape)\n",
    "\n",
    "    df =features[[ticker ] +additional_data]\n",
    "    print('df=features+additional data in module create_predict_set')\n",
    "    print(df)\n",
    "    \n",
    "    #duplicate last row of features to use in the lag - this is to add tomorrow date in the predict set\n",
    "    df_last=df.iloc[-1:]  #we get last date\n",
    "    print(df_last.index[-1])\n",
    "    print(type(df_last.index[-1]))\n",
    "    #last_date=datetime.fromtimestamp(df_last.index[-1]) #index is of type timestamp therefore convert to datetime\n",
    "    last_date=df_last.index[-1] #index is of type timestamp therefore convert to datetime\n",
    "    df=df.append(df_last)  #we append last date to end\n",
    "    df.index.array[-1] = last_date+timedelta(1) #we change to tomorrows date\n",
    "    #df.set_axis((df.index[:-1].union([last_date],sort=False)),axis=0)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    df_lagged =df.copy()\n",
    "    print(\"ici df lagged\", df_lagged)\n",
    "    for window in range(1, lags + 1):\n",
    "        shifted = df.shift(window)\n",
    "        shifted.columns = [x + \"_lag\" + str(window) for x in df.columns]\n",
    "\n",
    "        df_lagged = pd.concat((df_lagged, shifted), axis=1)\n",
    "    print('df_lagged of features+additional data before dropna in module create_predict_set')\n",
    "    print(df_lagged.shape)\n",
    "    print(df_lagged)\n",
    "    #df_lagged = df_lagged.fillna(method='ffill')\n",
    "    df_lagged= df_lagged.interpolate(method='linear')\n",
    "    df_lagged.to_csv('df_lagged3.csv')\n",
    "    df_lagged = df_lagged.dropna()\n",
    "    print('df_lagged of features+additional data after dropna and before sort in module create_predict_set')\n",
    "    print(df_lagged.shape)\n",
    "    df_lagged =df_lagged.reindex(sorted(df_lagged.columns), axis=1)\n",
    "    print('df_lagged of features+additional data after dropna in module create_predict_set')\n",
    "    print(df_lagged.shape)\n",
    "    print(df_lagged)\n",
    "    # test set\n",
    "    #df_filtered = df_lagged.loc[test_date_start:test_date_last]\n",
    "    df_filtered=df_lagged\n",
    "    \n",
    "    print('df_filtered which is only start to last date of predict  in module create_predict_set')\n",
    "    print(df_filtered.shape)\n",
    "    \n",
    "    X_test =df_filtered.drop(columns=[ticker])\n",
    "    y_test =df_filtered[ticker]\n",
    "\n",
    "    # we convert to numpy array\n",
    "    X_test =X_test.to_numpy()\n",
    "    y_test= y_test.to_numpy()\n",
    "    return X_test ,y_test ,df_filtered\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import bamboolib as bam\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import numpy as np\n",
    "from yahoo_fin import stock_info as si\n",
    "\n",
    "#from VBTT2_IO.IO import write_list, read_list,delete_then_get_model_from_bucket,read_config_file\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "#functions to fetch and process SP500 data\n",
    "\n",
    "def read_create_write_SP500(SP500_tickers,filename_json):\n",
    "    # This create the complete master list of all tickers in SP500, their sectors, their industries\n",
    "    # Check if SP500 json file exist first otherwise process SP500\n",
    "\n",
    "    check=delete_then_get_model_from_bucket(filename_json) #delete local file and copy file from bucket to have fresh one\n",
    "    #file_exists = os.path.exists(filename_json) #no longer required with blob check above\n",
    "\n",
    "    if check==True:\n",
    "        SP500_list = read_list(filename_json)\n",
    "        SP500_list = np.array(SP500_list)  # we need an array\n",
    "    else:\n",
    "        SP500_list = read_write_SP500(SP500_tickers,filename_json)  # this will extract\n",
    "\n",
    "    return SP500_list\n",
    "\n",
    "\n",
    "def get_ticker_sector(ticker):\n",
    "    # version 2\n",
    "    # prerequisites is to import Yahoo_finance.stock_info\n",
    "    # probleme avec cette methode c'est que industry est ligne 18 ou 19 *\n",
    "    # prerequisites 2 is to import pandas as pd; import numpy as np\n",
    "    filename_json=\"SP500.json\"\n",
    "    file_exists = os.path.exists(filename_json)\n",
    "    if file_exists:  # file json exist\n",
    "        SP500_list = read_list(filename_json)\n",
    "        SP500_list = np.array(SP500_list)  # we need an array\n",
    "        #now we should extract the sector which is column 2 for in each item of this 2D array\n",
    "        ticker_sector=SP500_list[:, 1:2][SP500_list[0:, 0:1] == ticker].tolist()\n",
    "\n",
    "        return ticker_sector[0]\n",
    "    else:\n",
    "        df = si.get_company_info(ticker)  # a utiliser pour trouver le secteur\n",
    "        df = df.reset_index()\n",
    "        sector = df.loc[df['Breakdown'].isin(['sector'])]  # from bamboolib to extract sector\n",
    "        sector = sector.iloc[0, 1]  # this is to extract just the value\n",
    "        industry = df.loc[df['Breakdown'].isin(['industry'])]\n",
    "        industry = industry.iloc[0, 1]\n",
    "        ticker_sector = []\n",
    "        ticker_sector.append([ticker, sector, industry])\n",
    "        return ticker_sector[0]\n",
    "\n",
    "\n",
    "def read_write_SP500(tickers_list,filename_json):\n",
    "    # Initialisation of SP500 data - find sector, industry for all tickers in SP500\n",
    "\n",
    "    SP500_list = []\n",
    "    for ticker in tickers_list:\n",
    "        print(\"ticker in module read_write_SP500\",ticker)\n",
    "        SP500_list.append(get_ticker_sector(ticker))\n",
    "        if len(SP500_list) % 30 == 0:\n",
    "            time.sleep(30)\n",
    "            # for some reason processing SP500 one shot is failing. so sleep of 20 seconds for each 50 tickers\n",
    "    SP500_list = np.array(SP500_list)\n",
    "    # Save in a file to reduce processing time next time\n",
    "    write_list(SP500_list.tolist(), filename_json)  # this function work if it is a list\n",
    "    return SP500_list  # this returns the array, not the list\n",
    "\n",
    "\n",
    "def get_all_tickers_sector(sector):\n",
    "    # prerequisites list is an array of ticker, sector and industry\n",
    "    filename_json = \"SP500.json\"\n",
    "    SP500_list = read_list(filename_json)\n",
    "    SP500_list = np.array(SP500_list)  # we need an array\n",
    "\n",
    "\n",
    "    sub_list_tickers = np.array(SP500_list)\n",
    "    fltr = np.asarray([sector])\n",
    "    result = sub_list_tickers[np.in1d(sub_list_tickers[:, 1], fltr)]\n",
    "    return result[:, 0:1]\n",
    "    # on veut extraire les tickers donc toutes les rangees (0:0) et la colonne 0 donc (0:1)\n",
    "\n",
    "\n",
    "def get_all_tickers_industry(industry):\n",
    "    # prerequisites list is an array of ticker, sector and industry\n",
    "    filename_json = \"SP500.json\"\n",
    "    SP500_list = read_list(filename_json)\n",
    "    SP500_list = np.array(SP500_list)  # we need an array\n",
    "\n",
    "    sub_list_tickers = np.array(SP500_list)\n",
    "    fltr = np.asarray([industry])\n",
    "    result = sub_list_tickers[np.in1d(sub_list_tickers[:, 2], fltr)]\n",
    "    return result[:, 0:1]\n",
    "    # on veut extraire les tickers donc toutes les rangees (0:0) et la colonne 0 donc (0:1)\n",
    "\n",
    "\n",
    "def generate_enhanced_data(sector,ticker):\n",
    "    additional_data = read_config_file()[1]\n",
    "    sector_list=get_all_tickers_sector(sector)\n",
    "    additional_data = np.concatenate((sector_list, additional_data), axis=None)\n",
    "    additional_data=additional_data.tolist()\n",
    "    additional_data.remove(ticker)\n",
    "    return additional_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'c', 'b', '1', '2']"
      ]
     },
     "execution_count": 896,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test1=['a','b','c','c','b']\n",
    "additional_data=['1','2','2']\n",
    "additional_data=np.concatenate((test1, additional_data), axis=None)\n",
    "additional_data=additional_data.tolist()\n",
    "additional_data.remove('2')\n",
    "additional_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'c', 'b', '1', '2']"
      ]
     },
     "execution_count": 897,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google.api.core in /home/steve/.local/lib/python3.10/site-packages (2.10.2)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/lib/python3/dist-packages (from google.api.core) (2.25.1)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /home/steve/.local/lib/python3.10/site-packages (from google.api.core) (2.14.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /home/steve/.local/lib/python3.10/site-packages (from google.api.core) (4.21.9)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /home/steve/.local/lib/python3.10/site-packages (from google.api.core) (1.56.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/steve/.local/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google.api.core) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/steve/.local/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google.api.core) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/steve/.local/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google.api.core) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from google-auth<3.0dev,>=1.25.0->google.api.core) (1.16.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/steve/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google.api.core) (0.4.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google.api.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-cloud-storage in /home/steve/.local/lib/python3.10/site-packages (2.5.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/lib/python3/dist-packages (from google-cloud-storage) (2.25.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /home/steve/.local/lib/python3.10/site-packages (from google-cloud-storage) (2.3.2)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /home/steve/.local/lib/python3.10/site-packages (from google-cloud-storage) (2.10.2)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /home/steve/.local/lib/python3.10/site-packages (from google-cloud-storage) (2.14.0)\n",
      "Requirement already satisfied: google-resumable-media>=2.3.2 in /home/steve/.local/lib/python3.10/site-packages (from google-cloud-storage) (2.4.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /home/steve/.local/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (4.21.9)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /home/steve/.local/lib/python3.10/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.56.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/steve/.local/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/steve/.local/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/steve/.local/lib/python3.10/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (1.16.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /home/steve/.local/lib/python3.10/site-packages (from google-resumable-media>=2.3.2->google-cloud-storage) (1.5.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/steve/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.4.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.api_core.exceptions import NotFound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import bamboolib as bam\n",
    "\n",
    "# Input Output functions to save and read files\n",
    "\n",
    "#import bamboolib as bam\n",
    "import json\n",
    "import configparser\n",
    "import logging\n",
    "import joblib\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_list(a_list, filename_json):\n",
    "    print(\"Started writing list data into a json file\")\n",
    "    with open(filename_json, \"w\") as fp:\n",
    "        json.dump(a_list, fp)\n",
    "        print(\"Done writing data into .json file\")\n",
    "    upload_file_to_bucket(filename_json)\n",
    "\n",
    "\n",
    "# Read list to memory\n",
    "def read_list(filename_json):\n",
    "    # for reading also binary mode is important\n",
    "    with open(filename_json, 'rb') as fp:\n",
    "        n_list = json.load(fp)\n",
    "        return n_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def read_config_file():\n",
    "    # return element that is in configfile. exemple additional data\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('config.ini')\n",
    "    version = config['DEFAULT']['version']\n",
    "    additional_data = config['DEFAULT']['additional_data'].split(',')\n",
    "    regressor = config['DEFAULT']['regressor']\n",
    "    model = config['DEFAULT']['model']\n",
    "    root_bucket=config['DEFAULT']['gcloud_root_bucket']\n",
    "\n",
    "    # ^TNX reasury yield is the annual return investors can expect from holding a U.S. government security with a given\n",
    "    # ^GSPC tracks the performance of the stocks of 500 large-cap companies in the US\"\n",
    "    # CL=F crude oil pricesi.get_data(result[0][0])\n",
    "\n",
    "    return version, additional_data,regressor, model, root_bucket\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#file existimport logging\n",
    "\n",
    "\n",
    "def create_bucket(bucket_name):\n",
    "    log = logging.getLogger()\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "    if bucket_name not in [x.name for x in storage_client.list_buckets()]:\n",
    "        bucket = storage_client.create_bucket(bucket_name)\n",
    "\n",
    "        log.info(\"Bucket {} created\".format(bucket.name))\n",
    "    else:\n",
    "        log.info(\"Bucket {} already exists\".format(bucket_name))\n",
    "\n",
    "\n",
    "\n",
    "def get_bucket_name():\n",
    "    root_bucket = read_config_file()[4]\n",
    "    version = read_config_file()[0]\n",
    "    bucket_name=f'{root_bucket}_{version.replace(\".\", \"\")}'\n",
    "    create_bucket(bucket_name)\n",
    "    return bucket_name\n",
    "\n",
    "\n",
    "def upload_file_to_bucket(model_file_name):\n",
    "    bucket_name=get_bucket_name()\n",
    "    log = logging.getLogger()\n",
    "    log.warning(f'uploading {model_file_name} to {bucket_name}')\n",
    "    storage_client = storage.Client()\n",
    "    bucket=storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(model_file_name)\n",
    "    blob.upload_from_filename(model_file_name)\n",
    "\n",
    "\n",
    "def delete_blob(blob_name):\n",
    "    log = logging.getLogger()\n",
    "    bucket_name = get_bucket_name()\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    blob.delete()\n",
    "    log.warning(f'old blob {blob_name} deleted from {bucket_name}\\n')\n",
    "\n",
    "\n",
    "def delete_then_get_model_from_bucket(model_filename):\n",
    "    log = logging.getLogger()\n",
    "    if (os.path.exists(model_filename)):\n",
    "        os.remove(model_filename)\n",
    "        log.warning(f'old file {model_filename} deleted locally\\n')\n",
    "\n",
    "    bucket_name = get_bucket_name()\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob=bucket.blob(model_filename)\n",
    "\n",
    "    try:\n",
    "        blob.download_to_filename(model_filename)\n",
    "        log.warning(f'new file   {model_filename} downloaded\\n')\n",
    "        return True #file download ok therefore retrain not required  or fileexists locally\n",
    "\n",
    "    except NotFound as e:\n",
    "        log.warning(f'file {model_filename} not found in bucket\\n')\n",
    "        return False  #retrain required or file does not exist locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from yahoo_fin import stock_info as si\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model_Train_Save(ticker_list_for_models, years, lags, additional_data, nb_predict_days):\n",
    "    # Functions for model training and algorythm data and import\n",
    "\n",
    "    # import the regressors\n",
    "    version, additional_data, regressor, MODEL,bucket=read_config_file()\n",
    "   \n",
    "\n",
    "    if MODEL=='DecisionTree()':\n",
    "        from sklearn.tree import DecisionTreeRegressor\n",
    "        MODEL = DecisionTreeRegressor()\n",
    "    elif MODEL=='LinearRegression()':\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        MODEL = LinearRegression()\n",
    "    elif MODEL=='svm.SVR()':\n",
    "        from sklearn import svm\n",
    "        MODEL = svm.SVR()\n",
    "    elif MODEL==\"DecisionTree(max_depth=5)\":\n",
    "        from sklearn.tree import DecisionTreeRegressor\n",
    "        MODEL = DecisionTreeRegressor(max_depth=5)\n",
    "    elif MODEL==\"Ridge(alpha=1.0)\":\n",
    "        from sklearn.linear_model import Ridge\n",
    "        MODEL=Ridge(alpha=1.0)\n",
    "    elif MODEL==\"Lasso(alpha=1.0)\":\n",
    "        from sklearn.linear_model import Lasso\n",
    "        MODEL=Lasso(alpha=1.0)\n",
    "    elif MODEL==\"xgboost\":\n",
    "        import xgboost as xgb\n",
    "        MODEL= xgb.XGBClassifier()\n",
    "    elif MODEL==\"RandomForestRegressor(n_estimators=100)\":   \n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        MODEL=RandomForestRegressor(n_estimators=100)\n",
    "    else:\n",
    "        #MODEL=='LinearRegression'\n",
    "        from sklearn.linear_model import LinearRegression\n",
    "        MODEL = LinearRegression()\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #### Initialisation of variables and data\n",
    "    # the timeframe for training and test sets and predict\n",
    "    days = 360 * years  # Nunber of days in the model\n",
    "    yesterday, start_date, train_date_start, train_date_last, test_date_start, test_date_last, days = initialize_data(\n",
    "        days,\n",
    "        lags,\n",
    "        nb_predict_days)\n",
    "    SP500_tickers = si.tickers_sp500()  # get list of tickers\n",
    "\n",
    "    # print(f\"SP500_tickers = {SP500_tickers}\")\n",
    "\n",
    "\n",
    "\n",
    "    # read master list of ticker, sector, industries or if not found, create it and save it#\n",
    "    SP500_list = read_create_write_SP500(SP500_tickers, \"SP500.json\")\n",
    "\n",
    "    ### validation if we have everything\n",
    "    # print(f\"Input ->years {years}\")\n",
    "    # print(f\"Input ->ticker list {ticker_list_for_models}\")\n",
    "    # print(f\"Input->lags {lags}\")\n",
    "    # print(f\"Input ->predict days {nb_predict_days}\")\n",
    "    # print(f\"Period->yesterday {yesterday}\")\n",
    "    # print(f\"period->train_date_start {train_date_start}\")\n",
    "    # print(f\"Period->train_date_last {train_date_last}\")\n",
    "    # print(f\"Period->test_date_start {test_date_start}\")\n",
    "    # print(f\"Period->test_date_last {test_date_last}\")\n",
    "\n",
    "    # print(f\"This is the tickers for our model {ticker_list_for_models}\")\n",
    "    # print(f\"This is the additional data  we add to the tickers for the model {additional_data}\")\n",
    "    # print(f\"VALIDATE - This is the number of training days of the train dataset {days}\")\n",
    "\n",
    "    # Get features\n",
    "    #matrix_features_sector = preprocessing(ticker_list_for_models, additional_data, days)\n",
    "\n",
    "    #### Run models for all tickers selected in input  and predict\n",
    "\n",
    "    predictions = pd.DataFrame()  # to store predictions\n",
    "\n",
    "    for ticker in ticker_list_for_models:\n",
    "        sector = get_ticker_sector(ticker)\n",
    "        additional_data = read_config_file()[1]\n",
    "        additional_data = generate_enhanced_data(sector,ticker)\n",
    "        print(\"in module model_Train_Save, additional_data\")\n",
    "        print(additional_data)\n",
    "\n",
    "        matrix_features_sector = preprocessing(ticker, additional_data, days)\n",
    "\n",
    "        X_train, y_train, X_test, y_test, df_filtered = create_train_test_set(ticker, matrix_features_sector, lags,additional_data,days,nb_predict_days)\n",
    "        \n",
    "        print(\"in module model_Train_Save, print model\")\n",
    "        print(MODEL)\n",
    "        print(\"in module model_Train_Save, print ticker\")\n",
    "        print(ticker)\n",
    "        MODEL.fit(X_train, y_train)\n",
    "        # save the model to disk\n",
    "        filename = ticker + '_model.sav'\n",
    "        joblib.dump(MODEL, filename)\n",
    "        upload_file_to_bucket(filename)\n",
    "        temp_pred = model_predict(MODEL, ticker, X_test, y_test)\n",
    "\n",
    "        predictions = predictions.append(temp_pred, ignore_index=True)  # this is to store in the master pandas list\n",
    "\n",
    "    # add binary buy=1 and sell=0\n",
    "    df_lagged = add_buy_sell_to_prediction(predictions,ticker_list_for_models)\n",
    "    df_lagged  # lag_lagged is a DF containing predictions + buy and Sell label\n",
    "\n",
    "    ticker = \"*all*\"\n",
    "    accuracy = balanced_accuracy(ticker, df_lagged)\n",
    "    print(f\"Accuracy score for {ticker} is {accuracy}.\")\n",
    "\n",
    "    accuracy = []\n",
    "    for ticker in ticker_list_for_models:\n",
    "        accuracy.append([balanced_accuracy(ticker, df_lagged), ticker])\n",
    "    DF_accuracy = pd.DataFrame(accuracy, columns=[\"Blc accuracy\", \"Ticker\"])\n",
    "    DF_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def balanced_accuracy(ticker, predict):\n",
    "    # put *all* to have global accuracy score for all the predictions\n",
    "    # or put a ticker name\n",
    "    if ticker == '*all*':\n",
    "        return balanced_accuracy_score(predict['y_testb'], predict['y_predb'])\n",
    "    else:\n",
    "        return balanced_accuracy_score(predict['y_testb'][predict['ticker'] == ticker],\n",
    "                                       predict['y_predb'][predict['ticker'] == ticker])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def model_predict(MODEL, ticker, X, y):\n",
    "    print('X test shape in module model_predict',X.shape)\n",
    "    y_pred = MODEL.predict(X)\n",
    "    temp_pred = predictions_compile(y, y_pred, ticker)  # this is to store temporary ytest, ypredict, ticker\n",
    "    return temp_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def predictions_compile(y_test, y_pred, ticker):\n",
    "    print(\"module predictions compile\")\n",
    "    print(\"y_test_shape in module predictions compile\",y_test.shape)\n",
    "    print(\"y_pred_shape in module predictions compile\",y_pred.shape)\n",
    "   \n",
    "    print (\"y_test in module predictions compile\", y_test)\n",
    "    print (\"y_pred in module predictions compile\",y_pred)\n",
    "    print (\"ticker in module predictions compile\",ticker)\n",
    "    # this allow to create a dataframe of y_test, y_predict for a given ticker\n",
    "    predict_df = pd.DataFrame({'y_test': y_test, 'y_pred': y_pred})\n",
    "    predict_df['ticker'] = ticker\n",
    "    print (\"predict_df in module predictions compile\",predict_df)\n",
    "    return predict_df\n",
    "    # we need to have an initial empty dataframe to store the predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def add_buy_sell_to_prediction(predictions, ticker_list_for_models):\n",
    "    # this section is to calculate the label=buy or sell\n",
    "    # it is adding colum y_testb and y_predictb to data frame predictions\n",
    "    # buy=1\n",
    "    # sell=0\n",
    "\n",
    "    df_lagged = pd.DataFrame()\n",
    "    for ticker in ticker_list_for_models:\n",
    "        df = predictions[predictions['ticker'] == ticker]\n",
    "        df_lagged_ticker = df.copy()\n",
    "        for window in range(1, 1 + 1):\n",
    "            shifted = df.shift(window)\n",
    "            shifted.columns = [x + \"_lag\" + str(window) for x in df.columns]\n",
    "\n",
    "            df_lagged_ticker = pd.concat((df_lagged_ticker, shifted), axis=1)\n",
    "            df_lagged_ticker = df_lagged_ticker.dropna()\n",
    "            df_lagged_ticker['y_testb'] = np.floor(df_lagged_ticker['y_test'] / df_lagged_ticker['y_test_lag1']).astype(\n",
    "                int)\n",
    "            df_lagged_ticker['y_predb'] = np.floor(df_lagged_ticker['y_pred'] / df_lagged_ticker['y_pred_lag1']).astype(\n",
    "                int)\n",
    "            # *** using map function to decide buy or sell\n",
    "            category = {1: \"Buy\", 0: \"Sell\"}\n",
    "            df_lagged_ticker['y_recommend'] = df_lagged_ticker['y_predb'].map(category)\n",
    "            df_lagged_ticker['daily return %'] = (\n",
    "                        (df_lagged_ticker['y_test'] / df_lagged_ticker['y_test_lag1']) - 1).where \\\n",
    "                (df_lagged_ticker['y_predb'] == 1, \\\n",
    "                 (((df_lagged_ticker['y_test_lag1'] / df_lagged_ticker['y_test']) - 1)))\n",
    "            df_lagged_ticker['daily return %'] = df_lagged_ticker['daily return %'] * 100\n",
    "        df_lagged = df_lagged.append(df_lagged_ticker)\n",
    "\n",
    "    return df_lagged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to predict model and calculate accuracy\n",
    "\n",
    "import os\n",
    "# import bamboolib as bam\n",
    "import os.path\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [],
   "source": [
    "def YF_datetime():\n",
    "    date_predict=datetime.now()\n",
    "    if date_predict.hour>=17:\n",
    "        date_predict=date_predict+timedelta(1)\n",
    "    return date_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ticker(ticker_list_for_models):\n",
    "    ticker_list_for_models = ticker_list_for_models.split('-')\n",
    "    # note when we use flask we will use /ticker/aapl-nflx-cdw\n",
    "    # so we need to split\n",
    "\n",
    "    # print(f\"Example long_test: {long_test}\")\n",
    "    # print(f\"Example short_test: {short_test}\")\n",
    "    # print(f\"Example not_working: {not_working}\")\n",
    "    # ticker_list_for_models=input_ticker\n",
    "\n",
    "    # initialisation model\n",
    "    # how many years for the model\n",
    "    years = 6\n",
    "    lags = 30  # how many days of lags we need of this model, this is like an hyperparameter for us\n",
    "    version, additional_data, regressor, model,bucket = read_config_file()  # other data needed\n",
    "    print(version)\n",
    "    print(regressor)\n",
    "    print(model)\n",
    "    print(additional_data)\n",
    "    print(bucket)\n",
    "\n",
    "    nb_predict_days = 30  # size of test data in number of days\n",
    "\n",
    "    # if we don't have model for a ticker in list, retrain model and save\n",
    "    check = True\n",
    "    for ticker in ticker_list_for_models:\n",
    "        check=delete_then_get_model_from_bucket(ticker + \"_model.sav\") #this download model from bucket. Model will be trained if model does not exist\n",
    "\n",
    "        if not (os.path.exists(ticker + \"_model.sav\")):\n",
    "            check = False\n",
    "            break  # this allow to continue and not go through the list if file not exist\n",
    "\n",
    "    if check == False:\n",
    "        #Retrain all for the select list of tickers\n",
    "        print(f\"Training model for at least one ticker in {ticker_list_for_models}\")\n",
    "        Model_Train_Save(ticker_list_for_models, years, lags, additional_data, nb_predict_days)\n",
    "    else:\n",
    "        print(f\"no model Training is needed for  {ticker_list_for_models}\")\n",
    "        ## get variable for start the prediction\n",
    "        ##just in case, we fetch 2 time the lags so that we don't have issue when lagging\n",
    "\n",
    "    yesterday, start_date, train_date_start, train_date_last, test_date_start, test_date_last, days = initialize_data(\n",
    "        lags * 2, lags, nb_predict_days)\n",
    "\n",
    "    ### validation if we have everything\n",
    "    print(f\"Input ->years {years}\")\n",
    "    print(f\"Input ->ticker list {ticker_list_for_models}\")\n",
    "    print(f\"Input->lags {lags}\")\n",
    "    print(f\"Input ->predict days {nb_predict_days}\")\n",
    "    print(f\"Period->yesterday {yesterday}\")\n",
    "    print(f\"period->train_date_start {train_date_start}\")\n",
    "    print(f\"Period->train_date_last {train_date_last}\")\n",
    "    print(f\"Period->test_date_start {test_date_start}\")\n",
    "    print(f\"Period->test_date_last {test_date_last}\")\n",
    "\n",
    "    print(f\"This is the tickers for our model {ticker_list_for_models}\")\n",
    "    print(f\"This is the additional data  we add to the tickers for the model {additional_data}\")\n",
    "\n",
    "    #df_tomorrow = preprocessing(ticker_list_for_models, additional_data, lags * 2)  # add additional features\n",
    "    #df_tomorrow.shape\n",
    "\n",
    "    # to store predictions\n",
    "    Predictions = pd.DataFrame()\n",
    "\n",
    "    for ticker in ticker_list_for_models:\n",
    "        # load the saved model for the ticker\n",
    "        filename = ticker + \"_model.sav\"\n",
    "        loaded_model = joblib.load(filename)\n",
    "        sector=get_ticker_sector(ticker)\n",
    "        additional_data=read_config_file()[1]\n",
    "        additional_data=generate_enhanced_data(sector,ticker)\n",
    "        print(additional_data)\n",
    "        df_tomorrow = preprocessing(ticker, additional_data, lags * 2)  # add additional features\n",
    "        print(\"predict df_tomorrow shape before creating predict set\")\n",
    "        print(df_tomorrow.shape)\n",
    "\n",
    "        X_test, y_test, df_filtered = create_predict_set(ticker, df_tomorrow, lags, nb_predict_days,\n",
    "                                                         additional_data)  # this is X and y\n",
    "\n",
    "        print(\"X_test shape in module predict_ticker before calling model_predict and after creating predict_set\",X_test.shape)\n",
    "\n",
    "\n",
    "        temp_pred = model_predict(loaded_model, ticker, X_test, y_test)\n",
    "        print(\"temp_pred shape in module predict_ticker after calling model_predict\",temp_pred.shape)\n",
    "\n",
    "        print(temp_pred)\n",
    "        # ===\n",
    "        temp_pred.drop(labels=[0], inplace=True)\n",
    "        temp_pred.to_csv('temp_pred.csv')\n",
    "\n",
    "        from datetime import timedelta\n",
    "\n",
    "        df_filtered2 = pd.DataFrame(df_filtered[ticker])\n",
    "\n",
    "        df_filtered2 = df_filtered2.reset_index()\n",
    "\n",
    "        # Deleted 1 row in df_filtered2\n",
    "        df_filtered2.drop(labels=[0], inplace=True)\n",
    "\n",
    "        # Renamed columns Date\n",
    "        df_filtered2.rename(columns={'index': 'Date'}, inplace=True)\n",
    "\n",
    "        df_filtered2['Predicted for'] = df_filtered2['Date'] \n",
    "        # df_filtered2['Prediction for']=df_filtered2['Date']\n",
    "        df_filtered2 = df_filtered2[['Date', 'Predicted for']]\n",
    "\n",
    "        # Step: Copy a dataframe column\n",
    "\n",
    "        temp_pred2 = pd.concat([temp_pred, df_filtered2], axis=1)\n",
    "\n",
    "        # ===\n",
    "\n",
    "        Predictions = Predictions.append(temp_pred2, ignore_index=True)  # this is to store in the master pandas list\n",
    "\n",
    "        # print(f\"temp_pred: \\n{temp_pred}\")\n",
    "        # print(f\"temp_pred2: \\n{temp_pred2}\")\n",
    "        # print(f\"temp_pred2: \\n{temp_pred2}\")\n",
    "        # print(f\"df_filtered2: \\n{df_filtered2}\")\n",
    "\n",
    "        # print(f\"Predictions:\\n {Predictions}\")\n",
    "\n",
    "    # adding binary buy or sell to predictions dataframe\n",
    "    Predictions = add_buy_sell_to_prediction(Predictions,ticker_list_for_models)\n",
    "    Predictions.to_csv('predictions.csv')\n",
    "\n",
    "    ticker = \"*all*\"\n",
    "    accuracy_all= balanced_accuracy(ticker, Predictions)\n",
    "    print(f\"Accuracy score for {ticker} is {accuracy_all}.\")\n",
    "    # provide a data frame of the accuracies\n",
    "\n",
    "    avg_return = [0]  # render for view html need a first element to be 0\n",
    "    for ticker in ticker_list_for_models:\n",
    "        ticker_return = round(Predictions['daily return %'][Predictions['ticker'] == ticker].iloc[:-1].mean(), 2)\n",
    "        avg_return.append(ticker_return)\n",
    "\n",
    "    DF_Recommendations = []\n",
    "    for ticker in ticker_list_for_models:\n",
    "        DF_Recommendations.append([ticker, \"\", \"\", \"\", balanced_accuracy(ticker, Predictions.iloc[:-1])])\n",
    "        Recommendations = pd.DataFrame(DF_Recommendations,\n",
    "                                       columns=[\"Ticker\", 'Predicted for', 'Predicted', \"Recommended\", \"Accuracy\"])\n",
    "\n",
    "    # ********************************************************\n",
    "    # suggestion - DF_accuracy change to DF_accuracy_recommendation\n",
    "    # suggestion - resultat change as follow: Date, Observed Value, Date Prediction, Predicted Value,Recommendation\n",
    "    # suggestion - now date observed value should be change to NA\n",
    "    # ********************************************************\n",
    "\n",
    "    for ticker in ticker_list_for_models:\n",
    "        # results = Predictions[['y_test', 'y_pred', 'ticker', 'y_predb','y_recommend']][Predictions['ticker'] == ticker]\n",
    "        results = Predictions[['y_test', 'y_pred', 'ticker', 'y_predb', 'y_recommend','daily return %']][Predictions['ticker'] == ticker]\n",
    "        date_predict=YF_datetime() #can be confusing but yesterday is datetime.now. good thing is to take latest in results +1\n",
    "        date_predict = date_predict.strftime(\"%Y/%m/%d\")\n",
    "        ticker_predicted = results.iloc[-1]['y_pred']  # this is the last row containing result\n",
    "        ticker_recommend = results.iloc[-1]['y_recommend']  # this is the last row containing result\n",
    "        Recommendations.loc[Recommendations['Ticker'] == ticker, 'Predicted for'] = date_predict  # to change content of a cell\n",
    "        Recommendations.loc[Recommendations['Ticker'] == ticker, 'Predicted'] = ticker_predicted\n",
    "        Recommendations.loc[Recommendations['Ticker'] == ticker, 'Recommended'] = ticker_recommend\n",
    "\n",
    "        Predictions.loc[(Predictions['Date']==date_predict) & (Predictions['ticker']==ticker),'y_test']=np.nan\n",
    "        Predictions.loc[(Predictions['Date']==date_predict) & (Predictions['ticker']==ticker),'daily return %']=np.nan\n",
    "           \n",
    "\n",
    "        # print(f\"Prediction for {yesterday+timedelta(1)} -- ticker: {ticker} {'**resultat**'}\\n {resultat.tail()}\\n\\n\")\n",
    "\n",
    "    Results = Predictions[['ticker', 'Date', 'y_test', 'Predicted for', 'y_pred', 'y_recommend','daily return %']]\n",
    "    Results = Results.rename(\n",
    "        columns={'ticker': 'Ticker', 'y_test': 'Observed', 'y_pred': 'Predicted', 'y_recommend': 'Recommended','daily return %':'Daily return %'})\n",
    "\n",
    "\n",
    "    return Results, Recommendations,avg_return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "from yahoo_fin import stock_info as si\n",
    "#from flask import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sp500():\n",
    "    SP500_tickers = si.tickers_sp500()\n",
    "    delete_blob(\"SP500.json\")\n",
    "    SP500_list = read_create_write_SP500(SP500_tickers, \"SP500.json\")\n",
    "    return f\"JSON was generated  successfully- try again with /ticker/xxx or /details/xxx (where xxx is your list of tickers separated by '-'.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_sp500()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_ticker(ticker):\n",
    "    ticker = ticker.upper()\n",
    "    version=read_config_file()[0]\n",
    "    model_html=read_config_file()[3]\n",
    "    filename_json=\"SP500.json\"\n",
    "    check=delete_then_get_model_from_bucket(filename_json)  # delete local file and copy file from bucket to have fresh one\n",
    "    #file_exists = os.path.exists(\"SP500.json\") # no longer required with blob check above\n",
    "    if check==True:  #file json exist\n",
    "        SP500_list = read_list(filename_json)\n",
    "        SP500_list = np.array(SP500_list)  # we need an array\n",
    "        validation=all([([x] in SP500_list[:,:1]) for x in ticker.split(\"-\")])\n",
    "        # all allow to check if a list o bolean is tru or false . all([true, false, true....etc])\n",
    "        # X in SP50_list, etc.... .... will check if x is in my SP500 list. here all row and column 0\n",
    "        # for x in is selecting each at a time\n",
    "\n",
    "        if validation==True:\n",
    "            Results, Recommendations,avg_return = predict_ticker(ticker)\n",
    "            print(\"avg return\",avg_return)\n",
    "            return Results, Recommendations,avg_return\n",
    "            \n",
    "\n",
    "        else:\n",
    "            return f\"Incorrect ticker, please fix or select another.\"\n",
    "    else:\n",
    "        return f\"JSON does not exists - Please generate JSON  with /get_SP500\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "old file SP500.json deleted locally\n",
      "\n",
      "new file   SP500.json downloaded\n",
      "\n",
      "old file CDW_model.sav deleted locally\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "*\n",
      "Lasso(alpha=1.0)\n",
      "['^tnx', '^GSPC', 'CL=F']\n",
      "stock-363101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "new file   CDW_model.sav downloaded\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no model Training is needed for  ['CDW']\n",
      "Input ->years 6\n",
      "Input ->ticker list ['CDW']\n",
      "Input->lags 30\n",
      "Input ->predict days 30\n",
      "Period->yesterday 2022-11-09 07:36:41.372472\n",
      "period->train_date_start 2022-09-10\n",
      "Period->train_date_last 2022-10-09\n",
      "Period->test_date_start 2022-10-10\n",
      "Period->test_date_last 2022-11-09\n",
      "This is the tickers for our model ['CDW']\n",
      "This is the additional data  we add to the tickers for the model ['^tnx', '^GSPC', 'CL=F']\n",
      "['AAPL', 'ACN', 'ADBE', 'ADI', 'ADSK', 'AKAM', 'AMAT', 'AMD', 'ANET', 'ANSS', 'APH', 'AVGO', 'BR', 'CDAY', 'CDNS', 'CRM', 'CSCO', 'CTSH', 'DXC', 'ENPH', 'EPAM', 'FFIV', 'FIS', 'FISV', 'FLT', 'FTNT', 'FTV', 'GLW', 'GRMN', 'HPE', 'HPQ', 'IBM', 'INTC', 'INTU', 'IT', 'JKHY', 'JNPR', 'KEYS', 'KLAC', 'LDOS', 'LRCX', 'MCHP', 'MPWR', 'MSFT', 'MSI', 'MU', 'NLOK', 'NOW', 'NTAP', 'NVDA', 'NXPI', 'ON', 'ORCL', 'PAYC', 'PTC', 'QCOM', 'QRVO', 'SEDG', 'SNPS', 'STX', 'SWKS', 'TDY', 'TEL', 'TER', 'TRMB', 'TXN', 'TYL', 'VRSN', 'WDC', 'ZBRA', '^tnx', '^GSPC', 'CL=F']\n",
      "preprocing module ticker CDW\n",
      "preprocessing module additional data ['AAPL', 'ACN', 'ADBE', 'ADI', 'ADSK', 'AKAM', 'AMAT', 'AMD', 'ANET', 'ANSS', 'APH', 'AVGO', 'BR', 'CDAY', 'CDNS', 'CRM', 'CSCO', 'CTSH', 'DXC', 'ENPH', 'EPAM', 'FFIV', 'FIS', 'FISV', 'FLT', 'FTNT', 'FTV', 'GLW', 'GRMN', 'HPE', 'HPQ', 'IBM', 'INTC', 'INTU', 'IT', 'JKHY', 'JNPR', 'KEYS', 'KLAC', 'LDOS', 'LRCX', 'MCHP', 'MPWR', 'MSFT', 'MSI', 'MU', 'NLOK', 'NOW', 'NTAP', 'NVDA', 'NXPI', 'ON', 'ORCL', 'PAYC', 'PTC', 'QCOM', 'QRVO', 'SEDG', 'SNPS', 'STX', 'SWKS', 'TDY', 'TEL', 'TER', 'TRMB', 'TXN', 'TYL', 'VRSN', 'WDC', 'ZBRA', '^tnx', '^GSPC', 'CL=F']\n",
      "preprocessing module days 60\n",
      "predict df_tomorrow shape before creating predict set\n",
      "(42, 74)\n",
      "features shape in module create_predict_set\n",
      "(42, 74)\n",
      "df=features+additional data in module create_predict_set\n",
      "                   CDW        AAPL         ACN        ADBE         ADI  \\\n",
      "2022-09-12  177.779999  163.429993  295.260010  396.359985  155.649994   \n",
      "2022-09-13  172.449997  153.839996  281.519989  368.390015  148.250000   \n",
      "2022-09-14  172.039993  155.309998  278.529999  371.519989  150.250000   \n",
      "2022-09-15  169.679993  152.369995  273.859985  309.130005  147.869995   \n",
      "2022-09-16  170.830002  150.699997  272.679993  299.500000  149.309998   \n",
      "2022-09-19  170.679993  154.479996  274.980011  296.059998  149.610001   \n",
      "2022-09-20  168.250000  156.899994  270.239990  291.059998  149.779999   \n",
      "2022-09-21  165.399994  153.720001  265.420013  286.299988  148.440002   \n",
      "2022-09-22  162.639999  152.740005  262.320007  287.059998  145.339996   \n",
      "2022-09-23  159.910004  150.429993  259.980011  284.559998  141.919998   \n",
      "2022-09-26  158.300003  150.770004  257.540009  276.959991  140.820007   \n",
      "2022-09-27  157.729996  151.759995  256.339996  277.570007  141.809998   \n",
      "2022-09-28  161.460007  149.839996  261.929993  281.399994  144.580002   \n",
      "2022-09-29  158.970001  142.479996  258.269989  278.250000  141.990005   \n",
      "2022-09-30  156.080002  138.199997  257.299988  275.200012  139.339996   \n",
      "2022-10-03  159.910004  142.449997  264.890015  285.239990  145.130005   \n",
      "2022-10-04  166.339996  146.100006  274.309998  294.970001  150.850006   \n",
      "2022-10-05  166.550003  146.399994  274.339996  297.380005  151.889999   \n",
      "2022-10-06  165.000000  145.429993  269.470001  298.410004  150.970001   \n",
      "2022-10-07  159.619995  140.089996  259.709991  288.769989  144.919998   \n",
      "2022-10-10  158.429993  140.419998  257.850006  285.720001  140.899994   \n",
      "2022-10-11  152.600006  138.979996  252.979996  284.829987  138.800003   \n",
      "2022-10-12  152.589996  138.339996  250.070007  286.149994  138.589996   \n",
      "2022-10-13  157.889999  142.990005  257.459991  294.739990  142.750000   \n",
      "2022-10-14  154.080002  138.380005  252.720001  287.940002  136.729996   \n",
      "2022-10-17  159.259995  142.410004  262.220001  293.500000  139.119995   \n",
      "2022-10-18  161.179993  143.750000  264.049988  292.980011  141.100006   \n",
      "2022-10-19  159.470001  143.860001  264.059998  299.829987  141.330002   \n",
      "2022-10-20  158.419998  143.389999  261.779999  302.380005  142.080002   \n",
      "2022-10-21  162.429993  147.270004  269.570007  306.369995  146.589996   \n",
      "2022-10-24  164.699997  149.449997  275.309998  316.220001  144.529999   \n",
      "2022-10-25  168.559998  152.339996  280.609985  323.790009  146.369995   \n",
      "2022-10-26  167.580002  149.350006  279.869995  320.480011  141.380005   \n",
      "2022-10-27  168.429993  144.800003  278.839996  318.649994  140.679993   \n",
      "2022-10-28  172.880005  155.740005  287.779999  325.679993  144.880005   \n",
      "2022-10-31  172.809998  153.339996  283.899994  318.500000  142.619995   \n",
      "2022-11-01  172.580002  150.649994  281.470001  316.019989  144.699997   \n",
      "2022-11-02  172.399994  145.029999  272.450012  301.220001  141.240005   \n",
      "2022-11-03  172.830002  138.880005  256.880005  285.929993  138.020004   \n",
      "2022-11-04  172.410004  138.380005  261.160004  285.750000  144.289993   \n",
      "2022-11-07  172.309998  138.919998  269.070007  299.540009  148.929993   \n",
      "2022-11-08  175.720001  139.500000  269.029999  302.170013  151.039993   \n",
      "\n",
      "                  ADSK       AKAM       AMAT        AMD        ANET  ...  \\\n",
      "2022-09-12  215.160004  93.110001  96.300003  84.639999  124.750000  ...   \n",
      "2022-09-13  208.339996  89.660004  90.389999  77.029999  119.919998  ...   \n",
      "2022-09-14  208.520004  89.389999  90.639999  77.449997  122.260002  ...   \n",
      "2022-09-15  201.300003  88.239998  88.919998  76.660004  116.940002  ...   \n",
      "2022-09-16  194.970001  87.160004  88.870003  76.510002  115.730003  ...   \n",
      "2022-09-19  196.889999  88.559998  89.720001  76.769997  114.940002  ...   \n",
      "2022-09-20  194.970001  85.930000  88.120003  75.250000  114.070000  ...   \n",
      "2022-09-21  192.419998  83.800003  87.089996  74.480003  113.820000  ...   \n",
      "2022-09-22  187.149994  82.089996  85.040001  69.500000  112.550003  ...   \n",
      "2022-09-23  184.559998  81.110001  84.290001  67.959999  109.970001  ...   \n",
      "2022-09-26  183.990005  80.709999  82.940002  66.300003  109.099998  ...   \n",
      "2022-09-27  187.960007  80.919998  84.150002  67.169998  110.919998  ...   \n",
      "2022-09-28  190.979996  82.250000  86.000000  68.360001  116.690002  ...   \n",
      "2022-09-29  189.460007  80.500000  84.419998  64.139999  114.750000  ...   \n",
      "2022-09-30  186.800003  80.320000  81.930000  63.360001  112.889999  ...   \n",
      "2022-10-03  192.460007  83.839996  86.250000  66.110001  115.830002  ...   \n",
      "2022-10-04  199.990005  87.160004  89.410004  67.900002  120.809998  ...   \n",
      "2022-10-05  204.529999  85.379997  89.220001  67.940002  121.349998  ...   \n",
      "2022-10-06  205.869995  84.440002  88.120003  67.849998  121.900002  ...   \n",
      "2022-10-07  194.740005  82.080002  82.599998  58.439999  116.410004  ...   \n",
      "2022-10-10  191.029999  79.879997  79.190002  57.810001  109.480003  ...   \n",
      "2022-10-11  191.029999  78.059998  76.300003  57.630001  107.050003  ...   \n",
      "2022-10-12  193.639999  78.410004  76.010002  57.849998  103.650002  ...   \n",
      "2022-10-13  193.850006  80.459999  79.419998  58.939999  103.910004  ...   \n",
      "2022-10-14  189.809998  79.980003  74.820000  55.939999  100.370003  ...   \n",
      "2022-10-17  198.699997  82.540001  74.410004  57.959999  104.559998  ...   \n",
      "2022-10-18  200.699997  84.379997  75.230003  57.919998  106.279999  ...   \n",
      "2022-10-19  197.020004  82.940002  77.260002  57.230000  105.110001  ...   \n",
      "2022-10-20  197.830002  84.160004  78.660004  57.770000  105.639999  ...   \n",
      "2022-10-21  201.389999  85.879997  82.419998  58.820000  110.519997  ...   \n",
      "2022-10-24  207.089996  86.389999  84.940002  58.700001  110.739998  ...   \n",
      "2022-10-25  215.720001  88.449997  87.529999  61.470001  112.629997  ...   \n",
      "2022-10-26  214.559998  86.760002  88.139999  59.730000  108.970001  ...   \n",
      "2022-10-27  210.149994  87.580002  86.540001  58.599998  119.129997  ...   \n",
      "2022-10-28  216.389999  89.209999  89.720001  62.009998  121.470001  ...   \n",
      "2022-10-31  214.300003  88.330002  88.290001  60.060001  120.860001  ...   \n",
      "2022-11-01  214.050003  88.099998  89.790001  59.660000  127.709999  ...   \n",
      "2022-11-02  199.380005  85.410004  87.760002  58.630001  125.040001  ...   \n",
      "2022-11-03  194.220001  83.360001  86.300003  60.110001  122.250000  ...   \n",
      "2022-11-04  193.690002  84.099998  91.699997  62.189999  131.070007  ...   \n",
      "2022-11-07  194.880005  83.860001  95.040001  63.080002  130.580002  ...   \n",
      "2022-11-08  199.009995  83.889999  97.459999  63.849998  129.110001  ...   \n",
      "\n",
      "                  TER       TRMB         TXN         TYL        VRSN  \\\n",
      "2022-09-12  87.379997  64.430000  170.580002  386.859985  189.039993   \n",
      "2022-09-13  83.160004  61.680000  162.649994  364.559998  178.750000   \n",
      "2022-09-14  83.639999  61.220001  165.259995  368.540009  178.339996   \n",
      "2022-09-15  82.349998  59.419998  162.669998  362.760010  174.619995   \n",
      "2022-09-16  82.099998  58.680000  165.259995  360.980011  175.029999   \n",
      "2022-09-19  82.489998  58.919998  166.250000  362.200012  176.270004   \n",
      "2022-09-20  80.839996  58.459999  166.059998  353.859985  174.729996   \n",
      "2022-09-21  80.970001  57.369999  163.300003  351.299988  176.720001   \n",
      "2022-09-22  79.790001  56.790001  162.619995  342.489990  174.639999   \n",
      "2022-09-23  79.190002  56.380001  161.289993  341.119995  173.699997   \n",
      "2022-09-26  77.209999  55.439999  160.460007  342.750000  173.380005   \n",
      "2022-09-27  78.370003  55.250000  160.710007  341.750000  172.529999   \n",
      "2022-09-28  78.949997  56.919998  162.800003  347.079987  177.289993   \n",
      "2022-09-29  77.169998  55.259998  158.449997  347.700012  176.169998   \n",
      "2022-09-30  75.150002  54.270000  154.779999  347.500000  173.699997   \n",
      "2022-10-03  78.690002  56.220001  159.839996  349.200012  179.300003   \n",
      "2022-10-04  81.669998  58.790001  165.149994  362.890015  183.460007   \n",
      "2022-10-05  81.949997  57.610001  167.800003  367.269989  183.869995   \n",
      "2022-10-06  82.010002  57.730000  166.539993  366.000000  182.080002   \n",
      "2022-10-07  77.330002  54.610001  159.279999  352.950012  177.860001   \n",
      "2022-10-10  76.110001  53.820000  156.789993  343.540009  176.990005   \n",
      "2022-10-11  74.019997  52.490002  153.449997  329.760010  174.889999   \n",
      "2022-10-12  72.000000  52.000000  151.550003  328.149994  175.679993   \n",
      "2022-10-13  75.110001  53.480000  154.339996  324.750000  176.850006   \n",
      "2022-10-14  71.370003  52.299999  148.339996  315.829987  174.080002   \n",
      "2022-10-17  71.510002  54.500000  150.990005  326.250000  179.550003   \n",
      "2022-10-18  72.779999  55.759998  151.509995  339.390015  182.889999   \n",
      "2022-10-19  73.180000  54.830002  152.649994  336.369995  182.100006   \n",
      "2022-10-20  73.949997  53.490002  153.720001  334.559998  178.669998   \n",
      "2022-10-21  77.269997  55.880001  159.720001  335.950012  179.149994   \n",
      "2022-10-24  77.459999  56.099998  161.649994  337.980011  182.199997   \n",
      "2022-10-25  79.650002  58.150002  162.160004  346.059998  187.820007   \n",
      "2022-10-26  82.250000  58.029999  157.869995  343.420013  184.990005   \n",
      "2022-10-27  79.860001  58.240002  156.759995  333.529999  185.789993   \n",
      "2022-10-28  83.349998  60.240002  161.360001  330.500000  203.369995   \n",
      "2022-10-31  81.349998  60.160000  160.630005  323.329987  200.460007   \n",
      "2022-11-01  82.220001  59.889999  162.899994  314.239990  196.970001   \n",
      "2022-11-02  79.440002  53.650002  158.490005  296.559998  186.610001   \n",
      "2022-11-03  80.089996  52.060001  156.520004  292.630005  180.190002   \n",
      "2022-11-04  84.720001  53.790001  162.649994  287.929993  176.690002   \n",
      "2022-11-07  85.540001  57.200001  165.690002  289.470001  177.880005   \n",
      "2022-11-08  86.449997  54.650002  168.110001  296.140015  180.729996   \n",
      "\n",
      "                  WDC        ZBRA   ^tnx        ^GSPC       CL=F  \n",
      "2022-09-12  43.270000  311.850006  3.362  4110.410156  87.779999  \n",
      "2022-09-13  39.320000  293.500000  3.422  3932.689941  87.309998  \n",
      "2022-09-14  38.330002  295.970001  3.412  3946.010010  88.480003  \n",
      "2022-09-15  37.770000  296.200012  3.459  3901.350098  85.099998  \n",
      "2022-09-16  37.220001  288.519989  3.448  3873.330078  85.110001  \n",
      "2022-09-19  36.619999  291.209991  3.490  3899.889893  85.730003  \n",
      "2022-09-20  35.540001  285.649994  3.571  3855.929932  84.449997  \n",
      "2022-09-21  34.779999  285.079987  3.510  3789.929932  82.940002  \n",
      "2022-09-22  33.820000  272.940002  3.708  3757.989990  83.489998  \n",
      "2022-09-23  33.840000  268.040009  3.697  3693.229980  78.739998  \n",
      "2022-09-26  32.400002  265.859985  3.878  3655.040039  76.709999  \n",
      "2022-09-27  32.720001  264.950012  3.964  3647.290039  78.500000  \n",
      "2022-09-28  33.150002  271.350006  3.705  3719.040039  82.150002  \n",
      "2022-09-29  32.180000  265.519989  3.747  3640.469971  81.230003  \n",
      "2022-09-30  32.549999  262.010010  3.804  3585.620117  79.489998  \n",
      "2022-10-03  34.049999  272.089996  3.651  3678.429932  83.629997  \n",
      "2022-10-04  36.459999  281.649994  3.617  3790.929932  86.519997  \n",
      "2022-10-05  37.169998  281.880005  3.759  3783.280029  87.760002  \n",
      "2022-10-06  37.060001  280.350006  3.826  3744.520020  88.449997  \n",
      "2022-10-07  35.740002  266.679993  3.883  3639.659912  92.639999  \n",
      "2022-10-10  34.660000  258.600006  3.888  3612.389893  91.129997  \n",
      "2022-10-11  34.820000  250.009995  3.939  3588.840088  89.349998  \n",
      "2022-10-12  34.279999  261.029999  3.902  3577.030029  87.269997  \n",
      "2022-10-13  35.099998  268.269989  3.952  3669.909912  89.110001  \n",
      "2022-10-14  33.720001  255.610001  4.010  3583.070068  85.610001  \n",
      "2022-10-17  33.889999  261.640015  4.015  3677.949951  85.459999  \n",
      "2022-10-18  33.610001  263.890015  3.998  3719.979980  82.820000  \n",
      "2022-10-19  33.360001  260.459991  4.127  3695.159912  85.550003  \n",
      "2022-10-20  33.470001  256.230011  4.226  3665.780029  85.980003  \n",
      "2022-10-21  34.860001  263.040009  4.213  3752.750000  85.050003  \n",
      "2022-10-24  34.919998  265.720001  4.234  3797.340088  84.580002  \n",
      "2022-10-25  35.290001  274.579987  4.108  3859.110107  85.320000  \n",
      "2022-10-26  35.279999  273.179993  4.015  3830.600098  87.910004  \n",
      "2022-10-27  34.340000  275.290009  3.937  3807.300049  89.080002  \n",
      "2022-10-28  35.500000  288.000000  4.010  3901.060059  87.900002  \n",
      "2022-10-31  34.369999  283.220001  4.077  3871.979980  86.529999  \n",
      "2022-11-01  35.700001  238.300003  4.052  3856.100098  88.370003  \n",
      "2022-11-02  34.580002  236.029999  4.059  3759.689941  90.000000  \n",
      "2022-11-03  33.709999  227.320007  4.124  3719.889893  88.169998  \n",
      "2022-11-04  35.439999  230.559998  4.156  3770.550049  92.610001  \n",
      "2022-11-07  36.619999  236.360001  4.214  3806.800049  91.790001  \n",
      "2022-11-08  36.520000  234.649994  4.126  3828.110107  88.910004  \n",
      "\n",
      "[42 rows x 74 columns]\n",
      "2022-11-08 00:00:00\n",
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n",
      "ici df lagged                    CDW        AAPL         ACN        ADBE         ADI  \\\n",
      "2022-09-12  177.779999  163.429993  295.260010  396.359985  155.649994   \n",
      "2022-09-13  172.449997  153.839996  281.519989  368.390015  148.250000   \n",
      "2022-09-14  172.039993  155.309998  278.529999  371.519989  150.250000   \n",
      "2022-09-15  169.679993  152.369995  273.859985  309.130005  147.869995   \n",
      "2022-09-16  170.830002  150.699997  272.679993  299.500000  149.309998   \n",
      "2022-09-19  170.679993  154.479996  274.980011  296.059998  149.610001   \n",
      "2022-09-20  168.250000  156.899994  270.239990  291.059998  149.779999   \n",
      "2022-09-21  165.399994  153.720001  265.420013  286.299988  148.440002   \n",
      "2022-09-22  162.639999  152.740005  262.320007  287.059998  145.339996   \n",
      "2022-09-23  159.910004  150.429993  259.980011  284.559998  141.919998   \n",
      "2022-09-26  158.300003  150.770004  257.540009  276.959991  140.820007   \n",
      "2022-09-27  157.729996  151.759995  256.339996  277.570007  141.809998   \n",
      "2022-09-28  161.460007  149.839996  261.929993  281.399994  144.580002   \n",
      "2022-09-29  158.970001  142.479996  258.269989  278.250000  141.990005   \n",
      "2022-09-30  156.080002  138.199997  257.299988  275.200012  139.339996   \n",
      "2022-10-03  159.910004  142.449997  264.890015  285.239990  145.130005   \n",
      "2022-10-04  166.339996  146.100006  274.309998  294.970001  150.850006   \n",
      "2022-10-05  166.550003  146.399994  274.339996  297.380005  151.889999   \n",
      "2022-10-06  165.000000  145.429993  269.470001  298.410004  150.970001   \n",
      "2022-10-07  159.619995  140.089996  259.709991  288.769989  144.919998   \n",
      "2022-10-10  158.429993  140.419998  257.850006  285.720001  140.899994   \n",
      "2022-10-11  152.600006  138.979996  252.979996  284.829987  138.800003   \n",
      "2022-10-12  152.589996  138.339996  250.070007  286.149994  138.589996   \n",
      "2022-10-13  157.889999  142.990005  257.459991  294.739990  142.750000   \n",
      "2022-10-14  154.080002  138.380005  252.720001  287.940002  136.729996   \n",
      "2022-10-17  159.259995  142.410004  262.220001  293.500000  139.119995   \n",
      "2022-10-18  161.179993  143.750000  264.049988  292.980011  141.100006   \n",
      "2022-10-19  159.470001  143.860001  264.059998  299.829987  141.330002   \n",
      "2022-10-20  158.419998  143.389999  261.779999  302.380005  142.080002   \n",
      "2022-10-21  162.429993  147.270004  269.570007  306.369995  146.589996   \n",
      "2022-10-24  164.699997  149.449997  275.309998  316.220001  144.529999   \n",
      "2022-10-25  168.559998  152.339996  280.609985  323.790009  146.369995   \n",
      "2022-10-26  167.580002  149.350006  279.869995  320.480011  141.380005   \n",
      "2022-10-27  168.429993  144.800003  278.839996  318.649994  140.679993   \n",
      "2022-10-28  172.880005  155.740005  287.779999  325.679993  144.880005   \n",
      "2022-10-31  172.809998  153.339996  283.899994  318.500000  142.619995   \n",
      "2022-11-01  172.580002  150.649994  281.470001  316.019989  144.699997   \n",
      "2022-11-02  172.399994  145.029999  272.450012  301.220001  141.240005   \n",
      "2022-11-03  172.830002  138.880005  256.880005  285.929993  138.020004   \n",
      "2022-11-04  172.410004  138.380005  261.160004  285.750000  144.289993   \n",
      "2022-11-07  172.309998  138.919998  269.070007  299.540009  148.929993   \n",
      "2022-11-08  175.720001  139.500000  269.029999  302.170013  151.039993   \n",
      "2022-11-09  175.720001  139.500000  269.029999  302.170013  151.039993   \n",
      "\n",
      "                  ADSK       AKAM       AMAT        AMD        ANET  ...  \\\n",
      "2022-09-12  215.160004  93.110001  96.300003  84.639999  124.750000  ...   \n",
      "2022-09-13  208.339996  89.660004  90.389999  77.029999  119.919998  ...   \n",
      "2022-09-14  208.520004  89.389999  90.639999  77.449997  122.260002  ...   \n",
      "2022-09-15  201.300003  88.239998  88.919998  76.660004  116.940002  ...   \n",
      "2022-09-16  194.970001  87.160004  88.870003  76.510002  115.730003  ...   \n",
      "2022-09-19  196.889999  88.559998  89.720001  76.769997  114.940002  ...   \n",
      "2022-09-20  194.970001  85.930000  88.120003  75.250000  114.070000  ...   \n",
      "2022-09-21  192.419998  83.800003  87.089996  74.480003  113.820000  ...   \n",
      "2022-09-22  187.149994  82.089996  85.040001  69.500000  112.550003  ...   \n",
      "2022-09-23  184.559998  81.110001  84.290001  67.959999  109.970001  ...   \n",
      "2022-09-26  183.990005  80.709999  82.940002  66.300003  109.099998  ...   \n",
      "2022-09-27  187.960007  80.919998  84.150002  67.169998  110.919998  ...   \n",
      "2022-09-28  190.979996  82.250000  86.000000  68.360001  116.690002  ...   \n",
      "2022-09-29  189.460007  80.500000  84.419998  64.139999  114.750000  ...   \n",
      "2022-09-30  186.800003  80.320000  81.930000  63.360001  112.889999  ...   \n",
      "2022-10-03  192.460007  83.839996  86.250000  66.110001  115.830002  ...   \n",
      "2022-10-04  199.990005  87.160004  89.410004  67.900002  120.809998  ...   \n",
      "2022-10-05  204.529999  85.379997  89.220001  67.940002  121.349998  ...   \n",
      "2022-10-06  205.869995  84.440002  88.120003  67.849998  121.900002  ...   \n",
      "2022-10-07  194.740005  82.080002  82.599998  58.439999  116.410004  ...   \n",
      "2022-10-10  191.029999  79.879997  79.190002  57.810001  109.480003  ...   \n",
      "2022-10-11  191.029999  78.059998  76.300003  57.630001  107.050003  ...   \n",
      "2022-10-12  193.639999  78.410004  76.010002  57.849998  103.650002  ...   \n",
      "2022-10-13  193.850006  80.459999  79.419998  58.939999  103.910004  ...   \n",
      "2022-10-14  189.809998  79.980003  74.820000  55.939999  100.370003  ...   \n",
      "2022-10-17  198.699997  82.540001  74.410004  57.959999  104.559998  ...   \n",
      "2022-10-18  200.699997  84.379997  75.230003  57.919998  106.279999  ...   \n",
      "2022-10-19  197.020004  82.940002  77.260002  57.230000  105.110001  ...   \n",
      "2022-10-20  197.830002  84.160004  78.660004  57.770000  105.639999  ...   \n",
      "2022-10-21  201.389999  85.879997  82.419998  58.820000  110.519997  ...   \n",
      "2022-10-24  207.089996  86.389999  84.940002  58.700001  110.739998  ...   \n",
      "2022-10-25  215.720001  88.449997  87.529999  61.470001  112.629997  ...   \n",
      "2022-10-26  214.559998  86.760002  88.139999  59.730000  108.970001  ...   \n",
      "2022-10-27  210.149994  87.580002  86.540001  58.599998  119.129997  ...   \n",
      "2022-10-28  216.389999  89.209999  89.720001  62.009998  121.470001  ...   \n",
      "2022-10-31  214.300003  88.330002  88.290001  60.060001  120.860001  ...   \n",
      "2022-11-01  214.050003  88.099998  89.790001  59.660000  127.709999  ...   \n",
      "2022-11-02  199.380005  85.410004  87.760002  58.630001  125.040001  ...   \n",
      "2022-11-03  194.220001  83.360001  86.300003  60.110001  122.250000  ...   \n",
      "2022-11-04  193.690002  84.099998  91.699997  62.189999  131.070007  ...   \n",
      "2022-11-07  194.880005  83.860001  95.040001  63.080002  130.580002  ...   \n",
      "2022-11-08  199.009995  83.889999  97.459999  63.849998  129.110001  ...   \n",
      "2022-11-09  199.009995  83.889999  97.459999  63.849998  129.110001  ...   \n",
      "\n",
      "                  TER       TRMB         TXN         TYL        VRSN  \\\n",
      "2022-09-12  87.379997  64.430000  170.580002  386.859985  189.039993   \n",
      "2022-09-13  83.160004  61.680000  162.649994  364.559998  178.750000   \n",
      "2022-09-14  83.639999  61.220001  165.259995  368.540009  178.339996   \n",
      "2022-09-15  82.349998  59.419998  162.669998  362.760010  174.619995   \n",
      "2022-09-16  82.099998  58.680000  165.259995  360.980011  175.029999   \n",
      "2022-09-19  82.489998  58.919998  166.250000  362.200012  176.270004   \n",
      "2022-09-20  80.839996  58.459999  166.059998  353.859985  174.729996   \n",
      "2022-09-21  80.970001  57.369999  163.300003  351.299988  176.720001   \n",
      "2022-09-22  79.790001  56.790001  162.619995  342.489990  174.639999   \n",
      "2022-09-23  79.190002  56.380001  161.289993  341.119995  173.699997   \n",
      "2022-09-26  77.209999  55.439999  160.460007  342.750000  173.380005   \n",
      "2022-09-27  78.370003  55.250000  160.710007  341.750000  172.529999   \n",
      "2022-09-28  78.949997  56.919998  162.800003  347.079987  177.289993   \n",
      "2022-09-29  77.169998  55.259998  158.449997  347.700012  176.169998   \n",
      "2022-09-30  75.150002  54.270000  154.779999  347.500000  173.699997   \n",
      "2022-10-03  78.690002  56.220001  159.839996  349.200012  179.300003   \n",
      "2022-10-04  81.669998  58.790001  165.149994  362.890015  183.460007   \n",
      "2022-10-05  81.949997  57.610001  167.800003  367.269989  183.869995   \n",
      "2022-10-06  82.010002  57.730000  166.539993  366.000000  182.080002   \n",
      "2022-10-07  77.330002  54.610001  159.279999  352.950012  177.860001   \n",
      "2022-10-10  76.110001  53.820000  156.789993  343.540009  176.990005   \n",
      "2022-10-11  74.019997  52.490002  153.449997  329.760010  174.889999   \n",
      "2022-10-12  72.000000  52.000000  151.550003  328.149994  175.679993   \n",
      "2022-10-13  75.110001  53.480000  154.339996  324.750000  176.850006   \n",
      "2022-10-14  71.370003  52.299999  148.339996  315.829987  174.080002   \n",
      "2022-10-17  71.510002  54.500000  150.990005  326.250000  179.550003   \n",
      "2022-10-18  72.779999  55.759998  151.509995  339.390015  182.889999   \n",
      "2022-10-19  73.180000  54.830002  152.649994  336.369995  182.100006   \n",
      "2022-10-20  73.949997  53.490002  153.720001  334.559998  178.669998   \n",
      "2022-10-21  77.269997  55.880001  159.720001  335.950012  179.149994   \n",
      "2022-10-24  77.459999  56.099998  161.649994  337.980011  182.199997   \n",
      "2022-10-25  79.650002  58.150002  162.160004  346.059998  187.820007   \n",
      "2022-10-26  82.250000  58.029999  157.869995  343.420013  184.990005   \n",
      "2022-10-27  79.860001  58.240002  156.759995  333.529999  185.789993   \n",
      "2022-10-28  83.349998  60.240002  161.360001  330.500000  203.369995   \n",
      "2022-10-31  81.349998  60.160000  160.630005  323.329987  200.460007   \n",
      "2022-11-01  82.220001  59.889999  162.899994  314.239990  196.970001   \n",
      "2022-11-02  79.440002  53.650002  158.490005  296.559998  186.610001   \n",
      "2022-11-03  80.089996  52.060001  156.520004  292.630005  180.190002   \n",
      "2022-11-04  84.720001  53.790001  162.649994  287.929993  176.690002   \n",
      "2022-11-07  85.540001  57.200001  165.690002  289.470001  177.880005   \n",
      "2022-11-08  86.449997  54.650002  168.110001  296.140015  180.729996   \n",
      "2022-11-09  86.449997  54.650002  168.110001  296.140015  180.729996   \n",
      "\n",
      "                  WDC        ZBRA   ^tnx        ^GSPC       CL=F  \n",
      "2022-09-12  43.270000  311.850006  3.362  4110.410156  87.779999  \n",
      "2022-09-13  39.320000  293.500000  3.422  3932.689941  87.309998  \n",
      "2022-09-14  38.330002  295.970001  3.412  3946.010010  88.480003  \n",
      "2022-09-15  37.770000  296.200012  3.459  3901.350098  85.099998  \n",
      "2022-09-16  37.220001  288.519989  3.448  3873.330078  85.110001  \n",
      "2022-09-19  36.619999  291.209991  3.490  3899.889893  85.730003  \n",
      "2022-09-20  35.540001  285.649994  3.571  3855.929932  84.449997  \n",
      "2022-09-21  34.779999  285.079987  3.510  3789.929932  82.940002  \n",
      "2022-09-22  33.820000  272.940002  3.708  3757.989990  83.489998  \n",
      "2022-09-23  33.840000  268.040009  3.697  3693.229980  78.739998  \n",
      "2022-09-26  32.400002  265.859985  3.878  3655.040039  76.709999  \n",
      "2022-09-27  32.720001  264.950012  3.964  3647.290039  78.500000  \n",
      "2022-09-28  33.150002  271.350006  3.705  3719.040039  82.150002  \n",
      "2022-09-29  32.180000  265.519989  3.747  3640.469971  81.230003  \n",
      "2022-09-30  32.549999  262.010010  3.804  3585.620117  79.489998  \n",
      "2022-10-03  34.049999  272.089996  3.651  3678.429932  83.629997  \n",
      "2022-10-04  36.459999  281.649994  3.617  3790.929932  86.519997  \n",
      "2022-10-05  37.169998  281.880005  3.759  3783.280029  87.760002  \n",
      "2022-10-06  37.060001  280.350006  3.826  3744.520020  88.449997  \n",
      "2022-10-07  35.740002  266.679993  3.883  3639.659912  92.639999  \n",
      "2022-10-10  34.660000  258.600006  3.888  3612.389893  91.129997  \n",
      "2022-10-11  34.820000  250.009995  3.939  3588.840088  89.349998  \n",
      "2022-10-12  34.279999  261.029999  3.902  3577.030029  87.269997  \n",
      "2022-10-13  35.099998  268.269989  3.952  3669.909912  89.110001  \n",
      "2022-10-14  33.720001  255.610001  4.010  3583.070068  85.610001  \n",
      "2022-10-17  33.889999  261.640015  4.015  3677.949951  85.459999  \n",
      "2022-10-18  33.610001  263.890015  3.998  3719.979980  82.820000  \n",
      "2022-10-19  33.360001  260.459991  4.127  3695.159912  85.550003  \n",
      "2022-10-20  33.470001  256.230011  4.226  3665.780029  85.980003  \n",
      "2022-10-21  34.860001  263.040009  4.213  3752.750000  85.050003  \n",
      "2022-10-24  34.919998  265.720001  4.234  3797.340088  84.580002  \n",
      "2022-10-25  35.290001  274.579987  4.108  3859.110107  85.320000  \n",
      "2022-10-26  35.279999  273.179993  4.015  3830.600098  87.910004  \n",
      "2022-10-27  34.340000  275.290009  3.937  3807.300049  89.080002  \n",
      "2022-10-28  35.500000  288.000000  4.010  3901.060059  87.900002  \n",
      "2022-10-31  34.369999  283.220001  4.077  3871.979980  86.529999  \n",
      "2022-11-01  35.700001  238.300003  4.052  3856.100098  88.370003  \n",
      "2022-11-02  34.580002  236.029999  4.059  3759.689941  90.000000  \n",
      "2022-11-03  33.709999  227.320007  4.124  3719.889893  88.169998  \n",
      "2022-11-04  35.439999  230.559998  4.156  3770.550049  92.610001  \n",
      "2022-11-07  36.619999  236.360001  4.214  3806.800049  91.790001  \n",
      "2022-11-08  36.520000  234.649994  4.126  3828.110107  88.910004  \n",
      "2022-11-09  36.520000  234.649994  4.126  3828.110107  88.910004  \n",
      "\n",
      "[43 rows x 74 columns]\n",
      "df_lagged of features+additional data before dropna in module create_predict_set\n",
      "(43, 2294)\n",
      "                   CDW        AAPL         ACN        ADBE         ADI  \\\n",
      "2022-09-12  177.779999  163.429993  295.260010  396.359985  155.649994   \n",
      "2022-09-13  172.449997  153.839996  281.519989  368.390015  148.250000   \n",
      "2022-09-14  172.039993  155.309998  278.529999  371.519989  150.250000   \n",
      "2022-09-15  169.679993  152.369995  273.859985  309.130005  147.869995   \n",
      "2022-09-16  170.830002  150.699997  272.679993  299.500000  149.309998   \n",
      "2022-09-19  170.679993  154.479996  274.980011  296.059998  149.610001   \n",
      "2022-09-20  168.250000  156.899994  270.239990  291.059998  149.779999   \n",
      "2022-09-21  165.399994  153.720001  265.420013  286.299988  148.440002   \n",
      "2022-09-22  162.639999  152.740005  262.320007  287.059998  145.339996   \n",
      "2022-09-23  159.910004  150.429993  259.980011  284.559998  141.919998   \n",
      "2022-09-26  158.300003  150.770004  257.540009  276.959991  140.820007   \n",
      "2022-09-27  157.729996  151.759995  256.339996  277.570007  141.809998   \n",
      "2022-09-28  161.460007  149.839996  261.929993  281.399994  144.580002   \n",
      "2022-09-29  158.970001  142.479996  258.269989  278.250000  141.990005   \n",
      "2022-09-30  156.080002  138.199997  257.299988  275.200012  139.339996   \n",
      "2022-10-03  159.910004  142.449997  264.890015  285.239990  145.130005   \n",
      "2022-10-04  166.339996  146.100006  274.309998  294.970001  150.850006   \n",
      "2022-10-05  166.550003  146.399994  274.339996  297.380005  151.889999   \n",
      "2022-10-06  165.000000  145.429993  269.470001  298.410004  150.970001   \n",
      "2022-10-07  159.619995  140.089996  259.709991  288.769989  144.919998   \n",
      "2022-10-10  158.429993  140.419998  257.850006  285.720001  140.899994   \n",
      "2022-10-11  152.600006  138.979996  252.979996  284.829987  138.800003   \n",
      "2022-10-12  152.589996  138.339996  250.070007  286.149994  138.589996   \n",
      "2022-10-13  157.889999  142.990005  257.459991  294.739990  142.750000   \n",
      "2022-10-14  154.080002  138.380005  252.720001  287.940002  136.729996   \n",
      "2022-10-17  159.259995  142.410004  262.220001  293.500000  139.119995   \n",
      "2022-10-18  161.179993  143.750000  264.049988  292.980011  141.100006   \n",
      "2022-10-19  159.470001  143.860001  264.059998  299.829987  141.330002   \n",
      "2022-10-20  158.419998  143.389999  261.779999  302.380005  142.080002   \n",
      "2022-10-21  162.429993  147.270004  269.570007  306.369995  146.589996   \n",
      "2022-10-24  164.699997  149.449997  275.309998  316.220001  144.529999   \n",
      "2022-10-25  168.559998  152.339996  280.609985  323.790009  146.369995   \n",
      "2022-10-26  167.580002  149.350006  279.869995  320.480011  141.380005   \n",
      "2022-10-27  168.429993  144.800003  278.839996  318.649994  140.679993   \n",
      "2022-10-28  172.880005  155.740005  287.779999  325.679993  144.880005   \n",
      "2022-10-31  172.809998  153.339996  283.899994  318.500000  142.619995   \n",
      "2022-11-01  172.580002  150.649994  281.470001  316.019989  144.699997   \n",
      "2022-11-02  172.399994  145.029999  272.450012  301.220001  141.240005   \n",
      "2022-11-03  172.830002  138.880005  256.880005  285.929993  138.020004   \n",
      "2022-11-04  172.410004  138.380005  261.160004  285.750000  144.289993   \n",
      "2022-11-07  172.309998  138.919998  269.070007  299.540009  148.929993   \n",
      "2022-11-08  175.720001  139.500000  269.029999  302.170013  151.039993   \n",
      "2022-11-09  175.720001  139.500000  269.029999  302.170013  151.039993   \n",
      "\n",
      "                  ADSK       AKAM       AMAT        AMD        ANET  ...  \\\n",
      "2022-09-12  215.160004  93.110001  96.300003  84.639999  124.750000  ...   \n",
      "2022-09-13  208.339996  89.660004  90.389999  77.029999  119.919998  ...   \n",
      "2022-09-14  208.520004  89.389999  90.639999  77.449997  122.260002  ...   \n",
      "2022-09-15  201.300003  88.239998  88.919998  76.660004  116.940002  ...   \n",
      "2022-09-16  194.970001  87.160004  88.870003  76.510002  115.730003  ...   \n",
      "2022-09-19  196.889999  88.559998  89.720001  76.769997  114.940002  ...   \n",
      "2022-09-20  194.970001  85.930000  88.120003  75.250000  114.070000  ...   \n",
      "2022-09-21  192.419998  83.800003  87.089996  74.480003  113.820000  ...   \n",
      "2022-09-22  187.149994  82.089996  85.040001  69.500000  112.550003  ...   \n",
      "2022-09-23  184.559998  81.110001  84.290001  67.959999  109.970001  ...   \n",
      "2022-09-26  183.990005  80.709999  82.940002  66.300003  109.099998  ...   \n",
      "2022-09-27  187.960007  80.919998  84.150002  67.169998  110.919998  ...   \n",
      "2022-09-28  190.979996  82.250000  86.000000  68.360001  116.690002  ...   \n",
      "2022-09-29  189.460007  80.500000  84.419998  64.139999  114.750000  ...   \n",
      "2022-09-30  186.800003  80.320000  81.930000  63.360001  112.889999  ...   \n",
      "2022-10-03  192.460007  83.839996  86.250000  66.110001  115.830002  ...   \n",
      "2022-10-04  199.990005  87.160004  89.410004  67.900002  120.809998  ...   \n",
      "2022-10-05  204.529999  85.379997  89.220001  67.940002  121.349998  ...   \n",
      "2022-10-06  205.869995  84.440002  88.120003  67.849998  121.900002  ...   \n",
      "2022-10-07  194.740005  82.080002  82.599998  58.439999  116.410004  ...   \n",
      "2022-10-10  191.029999  79.879997  79.190002  57.810001  109.480003  ...   \n",
      "2022-10-11  191.029999  78.059998  76.300003  57.630001  107.050003  ...   \n",
      "2022-10-12  193.639999  78.410004  76.010002  57.849998  103.650002  ...   \n",
      "2022-10-13  193.850006  80.459999  79.419998  58.939999  103.910004  ...   \n",
      "2022-10-14  189.809998  79.980003  74.820000  55.939999  100.370003  ...   \n",
      "2022-10-17  198.699997  82.540001  74.410004  57.959999  104.559998  ...   \n",
      "2022-10-18  200.699997  84.379997  75.230003  57.919998  106.279999  ...   \n",
      "2022-10-19  197.020004  82.940002  77.260002  57.230000  105.110001  ...   \n",
      "2022-10-20  197.830002  84.160004  78.660004  57.770000  105.639999  ...   \n",
      "2022-10-21  201.389999  85.879997  82.419998  58.820000  110.519997  ...   \n",
      "2022-10-24  207.089996  86.389999  84.940002  58.700001  110.739998  ...   \n",
      "2022-10-25  215.720001  88.449997  87.529999  61.470001  112.629997  ...   \n",
      "2022-10-26  214.559998  86.760002  88.139999  59.730000  108.970001  ...   \n",
      "2022-10-27  210.149994  87.580002  86.540001  58.599998  119.129997  ...   \n",
      "2022-10-28  216.389999  89.209999  89.720001  62.009998  121.470001  ...   \n",
      "2022-10-31  214.300003  88.330002  88.290001  60.060001  120.860001  ...   \n",
      "2022-11-01  214.050003  88.099998  89.790001  59.660000  127.709999  ...   \n",
      "2022-11-02  199.380005  85.410004  87.760002  58.630001  125.040001  ...   \n",
      "2022-11-03  194.220001  83.360001  86.300003  60.110001  122.250000  ...   \n",
      "2022-11-04  193.690002  84.099998  91.699997  62.189999  131.070007  ...   \n",
      "2022-11-07  194.880005  83.860001  95.040001  63.080002  130.580002  ...   \n",
      "2022-11-08  199.009995  83.889999  97.459999  63.849998  129.110001  ...   \n",
      "2022-11-09  199.009995  83.889999  97.459999  63.849998  129.110001  ...   \n",
      "\n",
      "            TER_lag30  TRMB_lag30   TXN_lag30   TYL_lag30  VRSN_lag30  \\\n",
      "2022-09-12        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-09-13        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-09-14        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-09-15        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-09-16        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-09-19        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-09-20        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-09-21        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-09-22        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-09-23        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-09-26        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-09-27        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-09-28        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-09-29        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-09-30        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-10-03        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-10-04        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-10-05        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-10-06        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-10-07        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-10-10        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-10-11        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-10-12        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-10-13        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-10-14        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-10-17        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-10-18        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-10-19        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-10-20        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-10-21        NaN         NaN         NaN         NaN         NaN   \n",
      "2022-10-24  87.379997   64.430000  170.580002  386.859985  189.039993   \n",
      "2022-10-25  83.160004   61.680000  162.649994  364.559998  178.750000   \n",
      "2022-10-26  83.639999   61.220001  165.259995  368.540009  178.339996   \n",
      "2022-10-27  82.349998   59.419998  162.669998  362.760010  174.619995   \n",
      "2022-10-28  82.099998   58.680000  165.259995  360.980011  175.029999   \n",
      "2022-10-31  82.489998   58.919998  166.250000  362.200012  176.270004   \n",
      "2022-11-01  80.839996   58.459999  166.059998  353.859985  174.729996   \n",
      "2022-11-02  80.970001   57.369999  163.300003  351.299988  176.720001   \n",
      "2022-11-03  79.790001   56.790001  162.619995  342.489990  174.639999   \n",
      "2022-11-04  79.190002   56.380001  161.289993  341.119995  173.699997   \n",
      "2022-11-07  77.209999   55.439999  160.460007  342.750000  173.380005   \n",
      "2022-11-08  78.370003   55.250000  160.710007  341.750000  172.529999   \n",
      "2022-11-09  78.949997   56.919998  162.800003  347.079987  177.289993   \n",
      "\n",
      "            WDC_lag30  ZBRA_lag30  ^tnx_lag30  ^GSPC_lag30  CL=F_lag30  \n",
      "2022-09-12        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-09-13        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-09-14        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-09-15        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-09-16        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-09-19        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-09-20        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-09-21        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-09-22        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-09-23        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-09-26        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-09-27        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-09-28        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-09-29        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-09-30        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-10-03        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-10-04        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-10-05        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-10-06        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-10-07        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-10-10        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-10-11        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-10-12        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-10-13        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-10-14        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-10-17        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-10-18        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-10-19        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-10-20        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-10-21        NaN         NaN         NaN          NaN         NaN  \n",
      "2022-10-24  43.270000  311.850006       3.362  4110.410156   87.779999  \n",
      "2022-10-25  39.320000  293.500000       3.422  3932.689941   87.309998  \n",
      "2022-10-26  38.330002  295.970001       3.412  3946.010010   88.480003  \n",
      "2022-10-27  37.770000  296.200012       3.459  3901.350098   85.099998  \n",
      "2022-10-28  37.220001  288.519989       3.448  3873.330078   85.110001  \n",
      "2022-10-31  36.619999  291.209991       3.490  3899.889893   85.730003  \n",
      "2022-11-01  35.540001  285.649994       3.571  3855.929932   84.449997  \n",
      "2022-11-02  34.779999  285.079987       3.510  3789.929932   82.940002  \n",
      "2022-11-03  33.820000  272.940002       3.708  3757.989990   83.489998  \n",
      "2022-11-04  33.840000  268.040009       3.697  3693.229980   78.739998  \n",
      "2022-11-07  32.400002  265.859985       3.878  3655.040039   76.709999  \n",
      "2022-11-08  32.720001  264.950012       3.964  3647.290039   78.500000  \n",
      "2022-11-09  33.150002  271.350006       3.705  3719.040039   82.150002  \n",
      "\n",
      "[43 rows x 2294 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1846559/1130624236.py:19: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df=df.append(df_last)  #we append last date to end\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_lagged of features+additional data after dropna and before sort in module create_predict_set\n",
      "(13, 2294)\n",
      "df_lagged of features+additional data after dropna in module create_predict_set\n",
      "(13, 2294)\n",
      "                  AAPL   AAPL_lag1  AAPL_lag10  AAPL_lag11  AAPL_lag12  \\\n",
      "2022-10-24  149.449997  147.270004  140.419998  140.089996  145.429993   \n",
      "2022-10-25  152.339996  149.449997  138.979996  140.419998  140.089996   \n",
      "2022-10-26  149.350006  152.339996  138.339996  138.979996  140.419998   \n",
      "2022-10-27  144.800003  149.350006  142.990005  138.339996  138.979996   \n",
      "2022-10-28  155.740005  144.800003  138.380005  142.990005  138.339996   \n",
      "2022-10-31  153.339996  155.740005  142.410004  138.380005  142.990005   \n",
      "2022-11-01  150.649994  153.339996  143.750000  142.410004  138.380005   \n",
      "2022-11-02  145.029999  150.649994  143.860001  143.750000  142.410004   \n",
      "2022-11-03  138.880005  145.029999  143.389999  143.860001  143.750000   \n",
      "2022-11-04  138.380005  138.880005  147.270004  143.389999  143.860001   \n",
      "2022-11-07  138.919998  138.380005  149.449997  147.270004  143.389999   \n",
      "2022-11-08  139.500000  138.919998  152.339996  149.449997  147.270004   \n",
      "2022-11-09  139.500000  139.500000  149.350006  152.339996  149.449997   \n",
      "\n",
      "            AAPL_lag13  AAPL_lag14  AAPL_lag15  AAPL_lag16  AAPL_lag17  ...  \\\n",
      "2022-10-24  146.399994  146.100006  142.449997  138.199997  142.479996  ...   \n",
      "2022-10-25  145.429993  146.399994  146.100006  142.449997  138.199997  ...   \n",
      "2022-10-26  140.089996  145.429993  146.399994  146.100006  142.449997  ...   \n",
      "2022-10-27  140.419998  140.089996  145.429993  146.399994  146.100006  ...   \n",
      "2022-10-28  138.979996  140.419998  140.089996  145.429993  146.399994  ...   \n",
      "2022-10-31  138.339996  138.979996  140.419998  140.089996  145.429993  ...   \n",
      "2022-11-01  142.990005  138.339996  138.979996  140.419998  140.089996  ...   \n",
      "2022-11-02  138.380005  142.990005  138.339996  138.979996  140.419998  ...   \n",
      "2022-11-03  142.410004  138.380005  142.990005  138.339996  138.979996  ...   \n",
      "2022-11-04  143.750000  142.410004  138.380005  142.990005  138.339996  ...   \n",
      "2022-11-07  143.860001  143.750000  142.410004  138.380005  142.990005  ...   \n",
      "2022-11-08  143.389999  143.860001  143.750000  142.410004  138.380005  ...   \n",
      "2022-11-09  147.270004  143.389999  143.860001  143.750000  142.410004  ...   \n",
      "\n",
      "            ^tnx_lag28  ^tnx_lag29  ^tnx_lag3  ^tnx_lag30  ^tnx_lag4  \\\n",
      "2022-10-24       3.412       3.422      4.127       3.362      3.998   \n",
      "2022-10-25       3.459       3.412      4.226       3.422      4.127   \n",
      "2022-10-26       3.448       3.459      4.213       3.412      4.226   \n",
      "2022-10-27       3.490       3.448      4.234       3.459      4.213   \n",
      "2022-10-28       3.571       3.490      4.108       3.448      4.234   \n",
      "2022-10-31       3.510       3.571      4.015       3.490      4.108   \n",
      "2022-11-01       3.708       3.510      3.937       3.571      4.015   \n",
      "2022-11-02       3.697       3.708      4.010       3.510      3.937   \n",
      "2022-11-03       3.878       3.697      4.077       3.708      4.010   \n",
      "2022-11-04       3.964       3.878      4.052       3.697      4.077   \n",
      "2022-11-07       3.705       3.964      4.059       3.878      4.052   \n",
      "2022-11-08       3.747       3.705      4.124       3.964      4.059   \n",
      "2022-11-09       3.804       3.747      4.156       3.705      4.124   \n",
      "\n",
      "            ^tnx_lag5  ^tnx_lag6  ^tnx_lag7  ^tnx_lag8  ^tnx_lag9  \n",
      "2022-10-24      4.015      4.010      3.952      3.902      3.939  \n",
      "2022-10-25      3.998      4.015      4.010      3.952      3.902  \n",
      "2022-10-26      4.127      3.998      4.015      4.010      3.952  \n",
      "2022-10-27      4.226      4.127      3.998      4.015      4.010  \n",
      "2022-10-28      4.213      4.226      4.127      3.998      4.015  \n",
      "2022-10-31      4.234      4.213      4.226      4.127      3.998  \n",
      "2022-11-01      4.108      4.234      4.213      4.226      4.127  \n",
      "2022-11-02      4.015      4.108      4.234      4.213      4.226  \n",
      "2022-11-03      3.937      4.015      4.108      4.234      4.213  \n",
      "2022-11-04      4.010      3.937      4.015      4.108      4.234  \n",
      "2022-11-07      4.077      4.010      3.937      4.015      4.108  \n",
      "2022-11-08      4.052      4.077      4.010      3.937      4.015  \n",
      "2022-11-09      4.059      4.052      4.077      4.010      3.937  \n",
      "\n",
      "[13 rows x 2294 columns]\n",
      "df_filtered which is only start to last date of predict  in module create_predict_set\n",
      "(13, 2294)\n",
      "X_test shape in module predict_ticker before calling model_predict and after creating predict_set (13, 2293)\n",
      "X test shape in module model_predict (13, 2293)\n",
      "module predictions compile\n",
      "y_test_shape in module predictions compile (13,)\n",
      "y_pred_shape in module predictions compile (13,)\n",
      "y_test in module predictions compile [164.69999695 168.55999756 167.58000183 168.42999268 172.88000488\n",
      " 172.80999756 172.58000183 172.3999939  172.83000183 172.41000366\n",
      " 172.30999756 175.72000122 175.72000122]\n",
      "y_pred in module predictions compile [163.31375126 166.88933447 167.5230639  167.75847905 173.63457797\n",
      " 173.02675098 172.37330016 169.82436691 170.16794494 173.28803972\n",
      " 173.98021013 174.04112711 175.36499787]\n",
      "ticker in module predictions compile CDW\n",
      "predict_df in module predictions compile         y_test      y_pred ticker\n",
      "0   164.699997  163.313751    CDW\n",
      "1   168.559998  166.889334    CDW\n",
      "2   167.580002  167.523064    CDW\n",
      "3   168.429993  167.758479    CDW\n",
      "4   172.880005  173.634578    CDW\n",
      "5   172.809998  173.026751    CDW\n",
      "6   172.580002  172.373300    CDW\n",
      "7   172.399994  169.824367    CDW\n",
      "8   172.830002  170.167945    CDW\n",
      "9   172.410004  173.288040    CDW\n",
      "10  172.309998  173.980210    CDW\n",
      "11  175.720001  174.041127    CDW\n",
      "12  175.720001  175.364998    CDW\n",
      "temp_pred shape in module predict_ticker after calling model_predict (13, 3)\n",
      "        y_test      y_pred ticker\n",
      "0   164.699997  163.313751    CDW\n",
      "1   168.559998  166.889334    CDW\n",
      "2   167.580002  167.523064    CDW\n",
      "3   168.429993  167.758479    CDW\n",
      "4   172.880005  173.634578    CDW\n",
      "5   172.809998  173.026751    CDW\n",
      "6   172.580002  172.373300    CDW\n",
      "7   172.399994  169.824367    CDW\n",
      "8   172.830002  170.167945    CDW\n",
      "9   172.410004  173.288040    CDW\n",
      "10  172.309998  173.980210    CDW\n",
      "11  175.720001  174.041127    CDW\n",
      "12  175.720001  175.364998    CDW\n",
      "Accuracy score for *all* is 0.75.\n",
      "avg return [0, 0.48]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1846559/2120334667.py:113: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  Predictions = Predictions.append(temp_pred2, ignore_index=True)  # this is to store in the master pandas list\n",
      "/tmp/ipykernel_1846559/1752493272.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_lagged = df_lagged.append(df_lagged_ticker)\n"
     ]
    }
   ],
   "source": [
    "ticker='CDW'\n",
    "results,recommendations,avg_return=check_ticker(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=b954a224-3275-4068-a8e8-a9f074863314 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('b954a224-3275-4068-a8e8-a9f074863314').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Observed</th>\n",
       "      <th>Predicted for</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Recommended</th>\n",
       "      <th>Daily return %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CDW</td>\n",
       "      <td>2022-10-26</td>\n",
       "      <td>167.580002</td>\n",
       "      <td>2022-10-26</td>\n",
       "      <td>167.523064</td>\n",
       "      <td>Buy</td>\n",
       "      <td>-0.581393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CDW</td>\n",
       "      <td>2022-10-27</td>\n",
       "      <td>168.429993</td>\n",
       "      <td>2022-10-27</td>\n",
       "      <td>167.758479</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.507215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CDW</td>\n",
       "      <td>2022-10-28</td>\n",
       "      <td>172.880005</td>\n",
       "      <td>2022-10-28</td>\n",
       "      <td>173.634578</td>\n",
       "      <td>Buy</td>\n",
       "      <td>2.642055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CDW</td>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>172.809998</td>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>173.026751</td>\n",
       "      <td>Sell</td>\n",
       "      <td>0.040511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CDW</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>172.580002</td>\n",
       "      <td>2022-11-01</td>\n",
       "      <td>172.373300</td>\n",
       "      <td>Sell</td>\n",
       "      <td>0.133269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CDW</td>\n",
       "      <td>2022-11-03</td>\n",
       "      <td>172.830002</td>\n",
       "      <td>2022-11-03</td>\n",
       "      <td>170.167945</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.249425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CDW</td>\n",
       "      <td>2022-11-04</td>\n",
       "      <td>172.410004</td>\n",
       "      <td>2022-11-04</td>\n",
       "      <td>173.288040</td>\n",
       "      <td>Buy</td>\n",
       "      <td>-0.243012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CDW</td>\n",
       "      <td>2022-11-07</td>\n",
       "      <td>172.309998</td>\n",
       "      <td>2022-11-07</td>\n",
       "      <td>173.980210</td>\n",
       "      <td>Buy</td>\n",
       "      <td>-0.058005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CDW</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>175.720001</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>174.041127</td>\n",
       "      <td>Buy</td>\n",
       "      <td>1.978994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>CDW</td>\n",
       "      <td>2022-11-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-09</td>\n",
       "      <td>175.364998</td>\n",
       "      <td>Buy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "   Ticker       Date    Observed Predicted for   Predicted Recommended  \\\n",
       "1     CDW 2022-10-26  167.580002    2022-10-26  167.523064         Buy   \n",
       "2     CDW 2022-10-27  168.429993    2022-10-27  167.758479         Buy   \n",
       "3     CDW 2022-10-28  172.880005    2022-10-28  173.634578         Buy   \n",
       "4     CDW 2022-10-31  172.809998    2022-10-31  173.026751        Sell   \n",
       "5     CDW 2022-11-01  172.580002    2022-11-01  172.373300        Sell   \n",
       "6     CDW 2022-11-02  172.399994    2022-11-02  169.824367        Sell   \n",
       "7     CDW 2022-11-03  172.830002    2022-11-03  170.167945         Buy   \n",
       "8     CDW 2022-11-04  172.410004    2022-11-04  173.288040         Buy   \n",
       "9     CDW 2022-11-07  172.309998    2022-11-07  173.980210         Buy   \n",
       "10    CDW 2022-11-08  175.720001    2022-11-08  174.041127         Buy   \n",
       "11    CDW 2022-11-09         NaN    2022-11-09  175.364998         Buy   \n",
       "\n",
       "    Daily return %  \n",
       "1        -0.581393  \n",
       "2         0.507215  \n",
       "3         2.642055  \n",
       "4         0.040511  \n",
       "5         0.133269  \n",
       "6         0.104413  \n",
       "7         0.249425  \n",
       "8        -0.243012  \n",
       "9        -0.058005  \n",
       "10        1.978994  \n",
       "11             NaN  "
      ]
     },
     "execution_count": 918,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=f787d28d-666f-4bb2-89ac-7fc5c09e7b72 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('f787d28d-666f-4bb2-89ac-7fc5c09e7b72').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Predicted for</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Recommended</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CDW</td>\n",
       "      <td>2022/11/09</td>\n",
       "      <td>175.364998</td>\n",
       "      <td>Buy</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "  Ticker Predicted for   Predicted Recommended  Accuracy\n",
       "0    CDW    2022/11/09  175.364998         Buy      0.75"
      ]
     },
     "execution_count": 919,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New section to see enhanced date and preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker='GOOG'\n",
    "sector=get_ticker_sector(ticker)\n",
    "additional_data=read_config_file()[1]\n",
    "additional_data=generate_enhanced_data(sector,ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocing module ticker GOOG\n",
      "preprocessing module additional data ['ATVI', 'CHTR', 'CMCSA', 'DIS', 'DISH', 'EA', 'FOX', 'FOXA', 'GOOGL', 'IPG', 'LUMN', 'LYV', 'META', 'MTCH', 'NFLX', 'NWS', 'NWSA', 'OMC', 'PARA', 'T', 'TMUS', 'TTWO', 'VZ', 'WBD', '^tnx', '^GSPC', 'CL=F']\n",
      "preprocessing module days 10\n"
     ]
    }
   ],
   "source": [
    "data=preprocessing(ticker,additional_data,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ATVI', 'Communication Services', 'Electronic Gaming & Multimedia'],\n",
       " ['CHTR', 'Communication Services', 'Telecom Services'],\n",
       " ['CMCSA', 'Communication Services', 'Telecom Services'],\n",
       " ['DIS', 'Communication Services', 'Entertainment'],\n",
       " ['DISH', 'Communication Services', 'Telecom Services'],\n",
       " ['EA', 'Communication Services', 'Electronic Gaming & Multimedia'],\n",
       " ['FOX', 'Communication Services', 'Entertainment'],\n",
       " ['FOXA', 'Communication Services', 'Entertainment'],\n",
       " ['GOOG', 'Communication Services', 'Internet Content & Information'],\n",
       " ['GOOGL', 'Communication Services', 'Internet Content & Information'],\n",
       " ['IPG', 'Communication Services', 'Advertising Agencies'],\n",
       " ['LUMN', 'Communication Services', 'Telecom Services'],\n",
       " ['LYV', 'Communication Services', 'Entertainment'],\n",
       " ['META', 'Communication Services', 'Internet Content & Information'],\n",
       " ['MTCH', 'Communication Services', 'Internet Content & Information'],\n",
       " ['NFLX', 'Communication Services', 'Entertainment'],\n",
       " ['NWS', 'Communication Services', 'Entertainment'],\n",
       " ['NWSA', 'Communication Services', 'Entertainment'],\n",
       " ['OMC', 'Communication Services', 'Advertising Agencies'],\n",
       " ['PARA', 'Communication Services', 'Entertainment'],\n",
       " ['T', 'Communication Services', 'Telecom Services'],\n",
       " ['TMUS', 'Communication Services', 'Telecom Services'],\n",
       " ['TTWO', 'Communication Services', 'Electronic Gaming & Multimedia'],\n",
       " ['VZ', 'Communication Services', 'Telecom Services'],\n",
       " ['WBD', 'Communication Services', 'Entertainment']]"
      ]
     },
     "execution_count": 922,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SP500_list = read_list(\"SP500.json\")\n",
    "#sub_list_tickers = np.array(SP500_list)\n",
    "fltr = np.asarray(\"Communication Services\")\n",
    "sector = sub_list_tickers[np.in1d(sub_list_tickers[:, 1], fltr)].tolist()\n",
    "sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=926b2d70-f2af-4682-a9e9-db2325e62090 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands?.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('926b2d70-f2af-4682-a9e9-db2325e62090').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ATVI</th>\n",
       "      <th>CHTR</th>\n",
       "      <th>CL=F</th>\n",
       "      <th>CMCSA</th>\n",
       "      <th>DIS</th>\n",
       "      <th>DISH</th>\n",
       "      <th>EA</th>\n",
       "      <th>FOX</th>\n",
       "      <th>FOXA</th>\n",
       "      <th>GOOG</th>\n",
       "      <th>...</th>\n",
       "      <th>NWSA</th>\n",
       "      <th>OMC</th>\n",
       "      <th>PARA</th>\n",
       "      <th>T</th>\n",
       "      <th>TMUS</th>\n",
       "      <th>TTWO</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WBD</th>\n",
       "      <th>^GSPC</th>\n",
       "      <th>^tnx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-10-31</th>\n",
       "      <td>72.800003</td>\n",
       "      <td>367.619995</td>\n",
       "      <td>86.529999</td>\n",
       "      <td>31.740000</td>\n",
       "      <td>106.540001</td>\n",
       "      <td>14.91</td>\n",
       "      <td>125.959999</td>\n",
       "      <td>27.200001</td>\n",
       "      <td>28.870001</td>\n",
       "      <td>94.660004</td>\n",
       "      <td>...</td>\n",
       "      <td>16.870001</td>\n",
       "      <td>72.750000</td>\n",
       "      <td>18.320000</td>\n",
       "      <td>18.230000</td>\n",
       "      <td>151.559998</td>\n",
       "      <td>118.480003</td>\n",
       "      <td>37.369999</td>\n",
       "      <td>13.00</td>\n",
       "      <td>3871.979980</td>\n",
       "      <td>4.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-01</th>\n",
       "      <td>73.309998</td>\n",
       "      <td>357.000000</td>\n",
       "      <td>88.370003</td>\n",
       "      <td>31.559999</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>15.06</td>\n",
       "      <td>126.269997</td>\n",
       "      <td>28.610001</td>\n",
       "      <td>30.530001</td>\n",
       "      <td>90.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.990000</td>\n",
       "      <td>73.099998</td>\n",
       "      <td>19.170000</td>\n",
       "      <td>18.350000</td>\n",
       "      <td>152.279999</td>\n",
       "      <td>116.309998</td>\n",
       "      <td>37.369999</td>\n",
       "      <td>13.35</td>\n",
       "      <td>3856.100098</td>\n",
       "      <td>4.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-02</th>\n",
       "      <td>72.660004</td>\n",
       "      <td>347.250000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>30.910000</td>\n",
       "      <td>101.820000</td>\n",
       "      <td>14.55</td>\n",
       "      <td>128.660004</td>\n",
       "      <td>28.170000</td>\n",
       "      <td>30.049999</td>\n",
       "      <td>87.070000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.469999</td>\n",
       "      <td>71.629997</td>\n",
       "      <td>16.790001</td>\n",
       "      <td>18.430000</td>\n",
       "      <td>150.020004</td>\n",
       "      <td>113.550003</td>\n",
       "      <td>37.709999</td>\n",
       "      <td>12.68</td>\n",
       "      <td>3759.689941</td>\n",
       "      <td>4.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-03</th>\n",
       "      <td>71.900002</td>\n",
       "      <td>344.250000</td>\n",
       "      <td>88.169998</td>\n",
       "      <td>30.379999</td>\n",
       "      <td>99.250000</td>\n",
       "      <td>13.72</td>\n",
       "      <td>126.620003</td>\n",
       "      <td>28.020000</td>\n",
       "      <td>29.950001</td>\n",
       "      <td>83.489998</td>\n",
       "      <td>...</td>\n",
       "      <td>16.459999</td>\n",
       "      <td>71.139999</td>\n",
       "      <td>16.209999</td>\n",
       "      <td>18.170000</td>\n",
       "      <td>148.169998</td>\n",
       "      <td>111.300003</td>\n",
       "      <td>37.150002</td>\n",
       "      <td>11.97</td>\n",
       "      <td>3719.889893</td>\n",
       "      <td>4.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-04</th>\n",
       "      <td>71.959999</td>\n",
       "      <td>348.820007</td>\n",
       "      <td>92.610001</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>99.580002</td>\n",
       "      <td>13.35</td>\n",
       "      <td>129.759995</td>\n",
       "      <td>27.830000</td>\n",
       "      <td>29.840000</td>\n",
       "      <td>86.699997</td>\n",
       "      <td>...</td>\n",
       "      <td>16.680000</td>\n",
       "      <td>72.220001</td>\n",
       "      <td>15.570000</td>\n",
       "      <td>18.320000</td>\n",
       "      <td>148.830002</td>\n",
       "      <td>108.529999</td>\n",
       "      <td>37.240002</td>\n",
       "      <td>10.43</td>\n",
       "      <td>3770.550049</td>\n",
       "      <td>4.156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-07</th>\n",
       "      <td>71.099998</td>\n",
       "      <td>353.279999</td>\n",
       "      <td>91.790001</td>\n",
       "      <td>31.600000</td>\n",
       "      <td>100.430000</td>\n",
       "      <td>14.67</td>\n",
       "      <td>132.419998</td>\n",
       "      <td>27.440001</td>\n",
       "      <td>29.139999</td>\n",
       "      <td>88.650002</td>\n",
       "      <td>...</td>\n",
       "      <td>16.719999</td>\n",
       "      <td>72.860001</td>\n",
       "      <td>16.370001</td>\n",
       "      <td>18.360001</td>\n",
       "      <td>149.779999</td>\n",
       "      <td>108.400002</td>\n",
       "      <td>37.189999</td>\n",
       "      <td>10.27</td>\n",
       "      <td>3806.800049</td>\n",
       "      <td>4.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-11-08</th>\n",
       "      <td>72.000000</td>\n",
       "      <td>354.660004</td>\n",
       "      <td>88.910004</td>\n",
       "      <td>31.900000</td>\n",
       "      <td>99.900002</td>\n",
       "      <td>15.34</td>\n",
       "      <td>129.100006</td>\n",
       "      <td>27.620001</td>\n",
       "      <td>29.340000</td>\n",
       "      <td>88.910004</td>\n",
       "      <td>...</td>\n",
       "      <td>17.090000</td>\n",
       "      <td>74.099998</td>\n",
       "      <td>16.580000</td>\n",
       "      <td>18.570000</td>\n",
       "      <td>149.899994</td>\n",
       "      <td>93.570000</td>\n",
       "      <td>37.869999</td>\n",
       "      <td>10.06</td>\n",
       "      <td>3828.110107</td>\n",
       "      <td>4.126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "                 ATVI        CHTR       CL=F      CMCSA         DIS   DISH  \\\n",
       "2022-10-31  72.800003  367.619995  86.529999  31.740000  106.540001  14.91   \n",
       "2022-11-01  73.309998  357.000000  88.370003  31.559999  106.000000  15.06   \n",
       "2022-11-02  72.660004  347.250000  90.000000  30.910000  101.820000  14.55   \n",
       "2022-11-03  71.900002  344.250000  88.169998  30.379999   99.250000  13.72   \n",
       "2022-11-04  71.959999  348.820007  92.610001  31.000000   99.580002  13.35   \n",
       "2022-11-07  71.099998  353.279999  91.790001  31.600000  100.430000  14.67   \n",
       "2022-11-08  72.000000  354.660004  88.910004  31.900000   99.900002  15.34   \n",
       "\n",
       "                    EA        FOX       FOXA       GOOG  ...       NWSA  \\\n",
       "2022-10-31  125.959999  27.200001  28.870001  94.660004  ...  16.870001   \n",
       "2022-11-01  126.269997  28.610001  30.530001  90.500000  ...  16.990000   \n",
       "2022-11-02  128.660004  28.170000  30.049999  87.070000  ...  16.469999   \n",
       "2022-11-03  126.620003  28.020000  29.950001  83.489998  ...  16.459999   \n",
       "2022-11-04  129.759995  27.830000  29.840000  86.699997  ...  16.680000   \n",
       "2022-11-07  132.419998  27.440001  29.139999  88.650002  ...  16.719999   \n",
       "2022-11-08  129.100006  27.620001  29.340000  88.910004  ...  17.090000   \n",
       "\n",
       "                  OMC       PARA          T        TMUS        TTWO  \\\n",
       "2022-10-31  72.750000  18.320000  18.230000  151.559998  118.480003   \n",
       "2022-11-01  73.099998  19.170000  18.350000  152.279999  116.309998   \n",
       "2022-11-02  71.629997  16.790001  18.430000  150.020004  113.550003   \n",
       "2022-11-03  71.139999  16.209999  18.170000  148.169998  111.300003   \n",
       "2022-11-04  72.220001  15.570000  18.320000  148.830002  108.529999   \n",
       "2022-11-07  72.860001  16.370001  18.360001  149.779999  108.400002   \n",
       "2022-11-08  74.099998  16.580000  18.570000  149.899994   93.570000   \n",
       "\n",
       "                   VZ    WBD        ^GSPC   ^tnx  \n",
       "2022-10-31  37.369999  13.00  3871.979980  4.077  \n",
       "2022-11-01  37.369999  13.35  3856.100098  4.052  \n",
       "2022-11-02  37.709999  12.68  3759.689941  4.059  \n",
       "2022-11-03  37.150002  11.97  3719.889893  4.124  \n",
       "2022-11-04  37.240002  10.43  3770.550049  4.156  \n",
       "2022-11-07  37.189999  10.27  3806.800049  4.214  \n",
       "2022-11-08  37.869999  10.06  3828.110107  4.126  \n",
       "\n",
       "[7 rows x 28 columns]"
      ]
     },
     "execution_count": 923,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xy=get_yf_dataframe(data,10)\n",
    "Xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
